{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c7bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefa8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>HappinessScore</th>\n",
       "      <th>GDP</th>\n",
       "      <th>SocialSupport</th>\n",
       "      <th>LifeExpectancy</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>Finland</td>\n",
       "      <td>7.736</td>\n",
       "      <td>1.7490</td>\n",
       "      <td>1.783000</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>7.521</td>\n",
       "      <td>1.8250</td>\n",
       "      <td>1.748000</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>7.515</td>\n",
       "      <td>1.7990</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>7.345</td>\n",
       "      <td>1.7830</td>\n",
       "      <td>1.698000</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>7.306</td>\n",
       "      <td>1.8220</td>\n",
       "      <td>1.667000</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>2011</td>\n",
       "      <td>152</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>3.678</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>2011</td>\n",
       "      <td>153</td>\n",
       "      <td>Sierra Leone</td>\n",
       "      <td>3.586</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>2011</td>\n",
       "      <td>154</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>3.568</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>2011</td>\n",
       "      <td>155</td>\n",
       "      <td>Benin</td>\n",
       "      <td>3.493</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>2011</td>\n",
       "      <td>156</td>\n",
       "      <td>Togo</td>\n",
       "      <td>3.007</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Rank                   Country  HappinessScore     GDP  \\\n",
       "0     2024     1                   Finland           7.736  1.7490   \n",
       "1     2024     2                   Denmark           7.521  1.8250   \n",
       "2     2024     3                   Iceland           7.515  1.7990   \n",
       "3     2024     4                    Sweden           7.345  1.7830   \n",
       "4     2024     5               Netherlands           7.306  1.8220   \n",
       "...    ...   ...                       ...             ...     ...   \n",
       "1951  2011   152                   Burundi           3.678  0.3674   \n",
       "1952  2011   153              Sierra Leone           3.586  0.3674   \n",
       "1953  2011   154  Central African Republic           3.568  0.3674   \n",
       "1954  2011   155                     Benin           3.493  0.3674   \n",
       "1955  2011   156                      Togo           3.007  0.3674   \n",
       "\n",
       "      SocialSupport  LifeExpectancy   Freedom  Generosity  Corruption  \n",
       "0          1.783000          0.8240  0.986000    0.110000    0.502000  \n",
       "1          1.748000          0.8200  0.955000    0.150000    0.488000  \n",
       "2          1.840000          0.8730  0.971000    0.201000    0.173000  \n",
       "3          1.698000          0.8890  0.952000    0.170000    0.467000  \n",
       "4          1.667000          0.8440  0.860000    0.186000    0.344000  \n",
       "...             ...             ...       ...         ...         ...  \n",
       "1951       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "1952       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "1953       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "1954       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "1955       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "\n",
       "[1956 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the World Happiness Report dataset\n",
    "df = pd.read_csv(\"/HappyLens-NN/data/happiness_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a0ac0",
   "metadata": {},
   "source": [
    "# === Model 5: LSTM on country sequences ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de6f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Year', 'GDP', 'SocialSupport', 'LifeExpectancy', 'Freedom', 'Generosity', 'Corruption']\n",
    "target = 'HappinessScore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d988272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM sequences with a 3-year window\n",
    "\n",
    "window_size = 3\n",
    "\n",
    "def create_sequences(data, features, target, window_size):\n",
    "    Xs, ys = [], []\n",
    "    countries = data[\"Country\"].unique()\n",
    "    for country in countries:\n",
    "        country_data = data[data[\"Country\"] == country].reset_index(drop=True)\n",
    "        for i in range(len(country_data) - window_size + 1):\n",
    "            seq = country_data.loc[i:i+window_size-1, features].values\n",
    "            target_val = country_data.loc[i+window_size-1, target]\n",
    "            Xs.append(seq)\n",
    "            ys.append(target_val)\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X, y = create_sequences(df, features, target, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c529c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and scale features\n",
    "num_samples, seq_len, num_features = X.shape\n",
    "X_2d = X.reshape(num_samples * seq_len, num_features)\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_2d_scaled = scaler.fit_transform(X_2d)\n",
    "X_scaled = X_2d_scaled.reshape(num_samples, seq_len, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0b3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split for sequences\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0d677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the LSTM model\n",
    "model5 = models.Sequential([\n",
    "    layers.Input(shape=(window_size, len(features))),\n",
    "    layers.LSTM(32, activation='tanh', return_sequences=False),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f3bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 28.7587 - mae: 5.2499 - val_loss: 23.9653 - val_mae: 4.7827\n",
      "Epoch 2/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.8054 - mae: 4.4014 - val_loss: 10.9071 - val_mae: 3.1013\n",
      "Epoch 3/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6983 - mae: 2.4442 - val_loss: 2.0515 - val_mae: 1.0929\n",
      "Epoch 4/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7078 - mae: 1.0374 - val_loss: 1.2535 - val_mae: 0.9189\n",
      "Epoch 5/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2322 - mae: 0.9040 - val_loss: 1.0150 - val_mae: 0.8092\n",
      "Epoch 6/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0601 - mae: 0.8286 - val_loss: 0.8961 - val_mae: 0.7460\n",
      "Epoch 7/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9374 - mae: 0.7585 - val_loss: 0.8298 - val_mae: 0.7163\n",
      "Epoch 8/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8227 - mae: 0.7137 - val_loss: 0.8183 - val_mae: 0.7113\n",
      "Epoch 9/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9065 - mae: 0.7483 - val_loss: 0.8048 - val_mae: 0.7052\n",
      "Epoch 10/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9479 - mae: 0.7613 - val_loss: 0.8037 - val_mae: 0.6985\n",
      "Epoch 11/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8790 - mae: 0.7271 - val_loss: 0.7790 - val_mae: 0.6916\n",
      "Epoch 12/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7976 - mae: 0.6875 - val_loss: 0.7607 - val_mae: 0.6827\n",
      "Epoch 13/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8377 - mae: 0.7022 - val_loss: 0.7792 - val_mae: 0.6887\n",
      "Epoch 14/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7981 - mae: 0.6952 - val_loss: 0.7627 - val_mae: 0.6764\n",
      "Epoch 15/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7874 - mae: 0.6827 - val_loss: 0.7731 - val_mae: 0.6791\n",
      "Epoch 16/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7588 - mae: 0.6735 - val_loss: 0.7701 - val_mae: 0.6774\n",
      "Epoch 17/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8472 - mae: 0.7183 - val_loss: 0.7717 - val_mae: 0.6748\n",
      "Epoch 18/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7667 - mae: 0.6626 - val_loss: 0.7340 - val_mae: 0.6640\n",
      "Epoch 19/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7842 - mae: 0.6858 - val_loss: 0.7427 - val_mae: 0.6637\n",
      "Epoch 20/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8087 - mae: 0.6929 - val_loss: 0.7506 - val_mae: 0.6645\n",
      "Epoch 21/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7729 - mae: 0.6745 - val_loss: 0.7467 - val_mae: 0.6618\n",
      "Epoch 22/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8424 - mae: 0.7034 - val_loss: 0.7236 - val_mae: 0.6545\n",
      "Epoch 23/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7550 - mae: 0.6637 - val_loss: 0.7320 - val_mae: 0.6526\n",
      "Epoch 24/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7906 - mae: 0.6725 - val_loss: 0.7294 - val_mae: 0.6521\n",
      "Epoch 25/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7557 - mae: 0.6527 - val_loss: 0.7213 - val_mae: 0.6499\n",
      "Epoch 26/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7273 - mae: 0.6469 - val_loss: 0.7242 - val_mae: 0.6497\n",
      "Epoch 27/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7462 - mae: 0.6491 - val_loss: 0.7293 - val_mae: 0.6532\n",
      "Epoch 28/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7482 - mae: 0.6601 - val_loss: 0.7346 - val_mae: 0.6541\n",
      "Epoch 29/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7361 - mae: 0.6525 - val_loss: 0.7113 - val_mae: 0.6437\n",
      "Epoch 30/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7036 - mae: 0.6318 - val_loss: 0.7100 - val_mae: 0.6428\n",
      "Epoch 31/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8075 - mae: 0.6916 - val_loss: 0.7158 - val_mae: 0.6446\n",
      "Epoch 32/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7493 - mae: 0.6494 - val_loss: 0.7182 - val_mae: 0.6446\n",
      "Epoch 33/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7818 - mae: 0.6667 - val_loss: 0.7195 - val_mae: 0.6441\n",
      "Epoch 34/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7652 - mae: 0.6624 - val_loss: 0.7852 - val_mae: 0.6661\n",
      "Epoch 35/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7677 - mae: 0.6606 - val_loss: 0.7235 - val_mae: 0.6451\n",
      "Epoch 36/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7920 - mae: 0.6732 - val_loss: 0.7378 - val_mae: 0.6486\n",
      "Epoch 37/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7481 - mae: 0.6653 - val_loss: 0.7865 - val_mae: 0.6630\n",
      "Epoch 38/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7577 - mae: 0.6558 - val_loss: 0.7515 - val_mae: 0.6515\n",
      "Epoch 39/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7541 - mae: 0.6474 - val_loss: 0.6982 - val_mae: 0.6321\n",
      "Epoch 40/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7261 - mae: 0.6405 - val_loss: 0.7144 - val_mae: 0.6382\n",
      "Epoch 41/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7284 - mae: 0.6410 - val_loss: 0.6959 - val_mae: 0.6306\n",
      "Epoch 42/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7374 - mae: 0.6387 - val_loss: 0.6931 - val_mae: 0.6266\n",
      "Epoch 43/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7118 - mae: 0.6291 - val_loss: 0.7040 - val_mae: 0.6321\n",
      "Epoch 44/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7545 - mae: 0.6516 - val_loss: 0.7068 - val_mae: 0.6321\n",
      "Epoch 45/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7299 - mae: 0.6296 - val_loss: 0.6941 - val_mae: 0.6260\n",
      "Epoch 46/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7462 - mae: 0.6455 - val_loss: 0.7006 - val_mae: 0.6272\n",
      "Epoch 47/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7569 - mae: 0.6474 - val_loss: 0.7100 - val_mae: 0.6340\n",
      "Epoch 48/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6964 - mae: 0.6276 - val_loss: 0.7090 - val_mae: 0.6316\n",
      "Epoch 49/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7494 - mae: 0.6409 - val_loss: 0.6898 - val_mae: 0.6232\n",
      "Epoch 50/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7087 - mae: 0.6364 - val_loss: 0.6954 - val_mae: 0.6268\n",
      "Epoch 51/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6899 - mae: 0.6255 - val_loss: 0.6890 - val_mae: 0.6210\n",
      "Epoch 52/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7668 - mae: 0.6664 - val_loss: 0.7162 - val_mae: 0.6291\n",
      "Epoch 53/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7029 - mae: 0.6156 - val_loss: 0.7390 - val_mae: 0.6409\n",
      "Epoch 54/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7078 - mae: 0.6254 - val_loss: 0.6881 - val_mae: 0.6219\n",
      "Epoch 55/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6553 - mae: 0.5985 - val_loss: 0.7171 - val_mae: 0.6296\n",
      "Epoch 56/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7535 - mae: 0.6311 - val_loss: 0.7100 - val_mae: 0.6267\n",
      "Epoch 57/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6726 - mae: 0.6040 - val_loss: 0.7488 - val_mae: 0.6416\n",
      "Epoch 58/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7709 - mae: 0.6570 - val_loss: 0.6836 - val_mae: 0.6172\n",
      "Epoch 59/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7203 - mae: 0.6250 - val_loss: 0.6982 - val_mae: 0.6240\n",
      "Epoch 60/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7145 - mae: 0.6264 - val_loss: 0.7242 - val_mae: 0.6338\n",
      "Epoch 61/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7489 - mae: 0.6424 - val_loss: 0.6824 - val_mae: 0.6159\n",
      "Epoch 62/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7030 - mae: 0.6249 - val_loss: 0.6846 - val_mae: 0.6178\n",
      "Epoch 63/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7192 - mae: 0.6302 - val_loss: 0.6826 - val_mae: 0.6147\n",
      "Epoch 64/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7130 - mae: 0.6270 - val_loss: 0.6847 - val_mae: 0.6151\n",
      "Epoch 65/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7023 - mae: 0.6134 - val_loss: 0.7044 - val_mae: 0.6222\n",
      "Epoch 66/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6880 - mae: 0.6173 - val_loss: 0.7059 - val_mae: 0.6244\n",
      "Epoch 67/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6270 - mae: 0.5761 - val_loss: 0.6808 - val_mae: 0.6146\n",
      "Epoch 68/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7764 - mae: 0.6592 - val_loss: 0.6770 - val_mae: 0.6107\n",
      "Epoch 69/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6492 - mae: 0.5870 - val_loss: 0.6815 - val_mae: 0.6142\n",
      "Epoch 70/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6794 - mae: 0.6082 - val_loss: 0.7035 - val_mae: 0.6224\n",
      "Epoch 71/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6945 - mae: 0.6164 - val_loss: 0.6781 - val_mae: 0.6132\n",
      "Epoch 72/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7416 - mae: 0.6375 - val_loss: 0.6909 - val_mae: 0.6160\n",
      "Epoch 73/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6850 - mae: 0.6146 - val_loss: 0.6711 - val_mae: 0.6069\n",
      "Epoch 74/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6944 - mae: 0.6080 - val_loss: 0.6824 - val_mae: 0.6117\n",
      "Epoch 75/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7116 - mae: 0.6217 - val_loss: 0.6716 - val_mae: 0.6069\n",
      "Epoch 76/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6911 - mae: 0.6209 - val_loss: 0.6969 - val_mae: 0.6194\n",
      "Epoch 77/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7227 - mae: 0.6306 - val_loss: 0.7253 - val_mae: 0.6309\n",
      "Epoch 78/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7233 - mae: 0.6352 - val_loss: 0.6723 - val_mae: 0.6062\n",
      "Epoch 79/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6698 - mae: 0.6019 - val_loss: 0.6909 - val_mae: 0.6137\n",
      "Epoch 80/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7494 - mae: 0.6335 - val_loss: 0.6988 - val_mae: 0.6210\n",
      "Epoch 81/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7432 - mae: 0.6335 - val_loss: 0.6968 - val_mae: 0.6154\n",
      "Epoch 82/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7016 - mae: 0.6167 - val_loss: 0.6784 - val_mae: 0.6085\n",
      "Epoch 83/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6939 - mae: 0.6122 - val_loss: 0.6683 - val_mae: 0.6062\n",
      "Epoch 84/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7097 - mae: 0.6257 - val_loss: 0.6683 - val_mae: 0.6051\n",
      "Epoch 85/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6823 - mae: 0.6145 - val_loss: 0.7001 - val_mae: 0.6148\n",
      "Epoch 86/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6799 - mae: 0.6057 - val_loss: 0.6695 - val_mae: 0.6076\n",
      "Epoch 87/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7154 - mae: 0.6342 - val_loss: 0.6678 - val_mae: 0.6044\n",
      "Epoch 88/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6876 - mae: 0.6060 - val_loss: 0.6796 - val_mae: 0.6108\n",
      "Epoch 89/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7090 - mae: 0.6183 - val_loss: 0.7070 - val_mae: 0.6159\n",
      "Epoch 90/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6809 - mae: 0.5978 - val_loss: 0.6698 - val_mae: 0.6061\n",
      "Epoch 91/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6661 - mae: 0.5981 - val_loss: 0.6713 - val_mae: 0.6075\n",
      "Epoch 92/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7021 - mae: 0.6180 - val_loss: 0.7097 - val_mae: 0.6174\n",
      "Epoch 93/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6673 - mae: 0.5993 - val_loss: 0.6709 - val_mae: 0.6059\n",
      "Epoch 94/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6452 - mae: 0.5836 - val_loss: 0.7212 - val_mae: 0.6248\n",
      "Epoch 95/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6964 - mae: 0.6165 - val_loss: 0.6828 - val_mae: 0.6114\n",
      "Epoch 96/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6845 - mae: 0.6086 - val_loss: 0.6767 - val_mae: 0.6050\n",
      "Epoch 97/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6555 - mae: 0.5963 - val_loss: 0.6681 - val_mae: 0.5999\n",
      "Epoch 98/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7880 - mae: 0.6565 - val_loss: 0.7430 - val_mae: 0.6323\n",
      "Epoch 99/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6984 - mae: 0.6113 - val_loss: 0.6641 - val_mae: 0.6056\n",
      "Epoch 100/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6956 - mae: 0.6107 - val_loss: 0.6743 - val_mae: 0.6018\n",
      "Epoch 101/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6905 - mae: 0.6066 - val_loss: 0.6886 - val_mae: 0.6124\n",
      "Epoch 102/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6770 - mae: 0.6001 - val_loss: 0.6627 - val_mae: 0.5962\n",
      "Epoch 103/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6992 - mae: 0.6147 - val_loss: 0.6773 - val_mae: 0.6042\n",
      "Epoch 104/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7118 - mae: 0.6183 - val_loss: 0.7203 - val_mae: 0.6305\n",
      "Epoch 105/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7026 - mae: 0.6083 - val_loss: 0.6665 - val_mae: 0.6027\n",
      "Epoch 106/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6857 - mae: 0.6140 - val_loss: 0.6730 - val_mae: 0.6048\n",
      "Epoch 107/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7025 - mae: 0.6184 - val_loss: 0.6804 - val_mae: 0.6061\n",
      "Epoch 108/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7299 - mae: 0.6225 - val_loss: 0.6898 - val_mae: 0.6119\n",
      "Epoch 109/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6462 - mae: 0.5799 - val_loss: 0.7117 - val_mae: 0.6231\n",
      "Epoch 110/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6591 - mae: 0.5834 - val_loss: 0.6816 - val_mae: 0.6081\n",
      "Epoch 111/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7313 - mae: 0.6274 - val_loss: 0.6700 - val_mae: 0.6022\n",
      "Epoch 112/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7134 - mae: 0.6143 - val_loss: 0.6715 - val_mae: 0.6016\n",
      "Epoch 113/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7090 - mae: 0.6144 - val_loss: 0.6714 - val_mae: 0.6079\n",
      "Epoch 114/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6819 - mae: 0.6008 - val_loss: 0.7119 - val_mae: 0.6236\n",
      "Epoch 115/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6844 - mae: 0.5996 - val_loss: 0.6754 - val_mae: 0.6025\n",
      "Epoch 116/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6695 - mae: 0.5953 - val_loss: 0.6842 - val_mae: 0.6033\n",
      "Epoch 117/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6787 - mae: 0.5989 - val_loss: 0.6621 - val_mae: 0.5983\n",
      "Epoch 118/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6774 - mae: 0.5984 - val_loss: 0.6750 - val_mae: 0.6025\n",
      "Epoch 119/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6830 - mae: 0.5975 - val_loss: 0.7247 - val_mae: 0.6259\n",
      "Epoch 120/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7422 - mae: 0.6247 - val_loss: 0.6913 - val_mae: 0.6152\n",
      "Epoch 121/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6856 - mae: 0.6015 - val_loss: 0.6837 - val_mae: 0.6080\n",
      "Epoch 122/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7117 - mae: 0.6161 - val_loss: 0.7270 - val_mae: 0.6280\n",
      "Epoch 123/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7216 - mae: 0.6149 - val_loss: 0.6687 - val_mae: 0.6041\n",
      "Epoch 124/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6559 - mae: 0.5901 - val_loss: 0.6612 - val_mae: 0.5951\n",
      "Epoch 125/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6514 - mae: 0.5921 - val_loss: 0.6802 - val_mae: 0.6062\n",
      "Epoch 126/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6772 - mae: 0.5985 - val_loss: 0.7061 - val_mae: 0.6242\n",
      "Epoch 127/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6409 - mae: 0.5772 - val_loss: 0.6636 - val_mae: 0.5972\n",
      "Epoch 128/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6706 - mae: 0.5938 - val_loss: 0.7133 - val_mae: 0.6244\n",
      "Epoch 129/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7338 - mae: 0.6213 - val_loss: 0.6827 - val_mae: 0.6132\n",
      "Epoch 130/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5993 - mae: 0.5672 - val_loss: 0.6630 - val_mae: 0.5982\n",
      "Epoch 131/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7871 - mae: 0.6418 - val_loss: 0.6611 - val_mae: 0.5985\n",
      "Epoch 132/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6643 - mae: 0.5966 - val_loss: 0.6818 - val_mae: 0.6049\n",
      "Epoch 133/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7341 - mae: 0.6184 - val_loss: 0.6708 - val_mae: 0.6061\n",
      "Epoch 134/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6926 - mae: 0.6044 - val_loss: 0.6726 - val_mae: 0.6025\n",
      "Epoch 135/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6827 - mae: 0.5938 - val_loss: 0.6648 - val_mae: 0.6027\n",
      "Epoch 136/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7138 - mae: 0.6178 - val_loss: 0.6832 - val_mae: 0.6049\n",
      "Epoch 137/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6905 - mae: 0.6093 - val_loss: 0.6935 - val_mae: 0.6065\n",
      "Epoch 138/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6808 - mae: 0.5965 - val_loss: 0.7345 - val_mae: 0.6344\n",
      "Epoch 139/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6860 - mae: 0.5989 - val_loss: 0.6634 - val_mae: 0.6004\n",
      "Epoch 140/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6894 - mae: 0.6030 - val_loss: 0.6602 - val_mae: 0.5958\n",
      "Epoch 141/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6838 - mae: 0.5993 - val_loss: 0.6873 - val_mae: 0.6141\n",
      "Epoch 142/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6672 - mae: 0.5854 - val_loss: 0.6814 - val_mae: 0.6051\n",
      "Epoch 143/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6640 - mae: 0.5874 - val_loss: 0.6599 - val_mae: 0.5962\n",
      "Epoch 144/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6728 - mae: 0.5898 - val_loss: 0.6644 - val_mae: 0.5984\n",
      "Epoch 145/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6205 - mae: 0.5672 - val_loss: 0.6746 - val_mae: 0.6015\n",
      "Epoch 146/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6801 - mae: 0.6038 - val_loss: 0.6853 - val_mae: 0.6105\n",
      "Epoch 147/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6372 - mae: 0.5818 - val_loss: 0.6836 - val_mae: 0.6129\n",
      "Epoch 148/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6589 - mae: 0.5884 - val_loss: 0.7487 - val_mae: 0.6393\n",
      "Epoch 149/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7222 - mae: 0.6107 - val_loss: 0.6762 - val_mae: 0.6108\n",
      "Epoch 150/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6718 - mae: 0.5860 - val_loss: 0.6829 - val_mae: 0.6141\n",
      "Epoch 151/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7169 - mae: 0.6045 - val_loss: 0.6646 - val_mae: 0.6033\n",
      "Epoch 152/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6699 - mae: 0.5924 - val_loss: 0.6773 - val_mae: 0.6030\n",
      "Epoch 153/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6474 - mae: 0.5743 - val_loss: 0.6709 - val_mae: 0.5993\n",
      "Epoch 154/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6681 - mae: 0.5856 - val_loss: 0.7039 - val_mae: 0.6182\n",
      "Epoch 155/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6785 - mae: 0.5806 - val_loss: 0.6659 - val_mae: 0.5993\n",
      "Epoch 156/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6548 - mae: 0.5805 - val_loss: 0.6659 - val_mae: 0.6019\n",
      "Epoch 157/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7180 - mae: 0.6038 - val_loss: 0.6639 - val_mae: 0.5984\n",
      "Epoch 158/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6776 - mae: 0.5842 - val_loss: 0.6640 - val_mae: 0.5985\n"
     ]
    }
   ],
   "source": [
    "# Train with early stopping\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model5.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "143346fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.6801, MAE: 0.6007\n",
      "Validation MSE: 0.6599, MAE: 0.5962\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_mse5, train_mae5 = model5.evaluate(X_train, y_train, verbose=0)\n",
    "val_mse5, val_mae5 = model5.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print(f\"Train MSE: {train_mse5:.4f}, MAE: {train_mae5:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse5:.4f}, MAE: {val_mae5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e5a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukraine 2024 Prediction (LSTM): 5.334\n",
      "Ukraine 2024 Actual: 4.68\n"
     ]
    }
   ],
   "source": [
    "# Predict Ukraine's Happiness Score in 2024 using last 3 years\n",
    "\n",
    "ukraine_data = df[df[\"Country\"] == \"Ukraine\"].sort_values(\"Year\")\n",
    "ukraine_seq = ukraine_data[features].iloc[-window_size:].values\n",
    "ukraine_seq_scaled = scaler.transform(ukraine_seq).reshape(1, window_size, len(features))\n",
    "\n",
    "ukraine_pred5 = model5.predict(ukraine_seq_scaled, verbose=0)[0][0]\n",
    "ukraine_actual = ukraine_data[target].iloc[-1]\n",
    "\n",
    "print(f\"Ukraine 2024 Prediction (LSTM): {ukraine_pred5:.3f}\")\n",
    "print(f\"Ukraine 2024 Actual: {ukraine_actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f933d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# --- Scenario simulation for Ukraine 2024 with 3-year sequence ---\n",
    "\n",
    "ukraine_seq = df[(df[\"Country\"] == \"Ukraine\") & (df[\"Year\"].isin([2022, 2023, 2024]))]\n",
    "ukraine_seq = ukraine_seq.sort_values(\"Year\").reset_index(drop=True)\n",
    "scenario = ukraine_seq.copy()\n",
    "\n",
    "# Apply artificial improvements\n",
    "scenario.loc[scenario[\"Year\"] == 2024, \"GDP\"] *= 1.10\n",
    "scenario.loc[scenario[\"Year\"] == 2024, \"SocialSupport\"] += 0.1\n",
    "scenario.loc[scenario[\"Year\"] == 2024, \"Freedom\"] += 0.1\n",
    "\n",
    "# Prepare data for prediction\n",
    "X_scenario = scenario[features].values.reshape(1, len(scenario), len(features))\n",
    "X_scenario_scaled = scaler.transform(X_scenario.reshape(-1, len(features))).reshape(1, len(scenario), len(features))\n",
    "\n",
    "# Predict new happiness score after simulated improvements\n",
    "predicted_score = model5.predict(X_scenario_scaled)[0][0]\n",
    "real_score = ukraine_seq.loc[ukraine_seq[\"Year\"] == 2024, \"HappinessScore\"].values[0]\n",
    "\n",
    "# Replace this with your actual OpenAI key\n",
    "# client = OpenAI(api_key=\"your-api-key\") \n",
    "\n",
    "# === GenAI Explanation ===\n",
    "\n",
    "def genai_explanation(gdp, support, freedom, predicted, real):\n",
    "    prompt = f\"\"\"\n",
    "Country: Ukraine\n",
    "Year: 2024\n",
    "The following socio-economic indicators were increased:\n",
    "- GDP by 10% (to {gdp:.3f})\n",
    "- Social Support by +0.1 (to {support:.3f})\n",
    "- Freedom by +0.1 (to {freedom:.3f})\n",
    "\n",
    "Predicted Happiness Score after intervention: {predicted:.2f}\n",
    "Actual Happiness Score for 2024: {real:.2f}\n",
    "\n",
    "Explain how these changes might influence the well-being and life satisfaction of Ukrainians in a short narrative, comparing predicted and actual values.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a policy analyst and social researcher.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gdp = scenario.loc[scenario[\"Year\"] == 2024, \"GDP\"].values[0]\n",
    "support = scenario.loc[scenario[\"Year\"] == 2024, \"SocialSupport\"].values[0]\n",
    "freedom = scenario.loc[scenario[\"Year\"] == 2024, \"Freedom\"].values[0]\n",
    "\n",
    "explanation = genai_explanation(gdp, support, freedom, predicted_score, real_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dcbaf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##  Scenario Simulation: Ukraine 2024\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**- Predicted Happiness Score (with improvements)**: `5.44`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**- Actual Happiness Score (2024)**: `4.68`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**- Difference**: `0.76` points difference"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##  GenAI Explanation:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An increase in the indicators - GDP, Social Support, and Freedom - in Ukraine in 2024 theoretically suggests an improvement in the overall well-being and life satisfaction of the Ukrainian people. The Gross Domestic Product (GDP) growth of 10% is indicative of an economic upswing and should contribute positively to the standard of living. This growth could mean more job opportunities, higher wages, and a healthier economy overall. \n",
       "\n",
       "The increase in Social Support is a strong determinant of well-being. This 0.1 positive shift indicates stronger public services, more robust community support networks, better access to healthcare, and possibly more efficient social safety nets. This could lead to less stress, less financial instability, and an overall higher quality of life for individuals.\n",
       "\n",
       "Moreover, the augmentation in Freedom by 0.1 signifies more civil liberties, democratic participation, and personal rights in Ukraine. This increase in Freedom tends to lead to higher life satisfaction as it gives individuals the rights to make choices about their lives, providing a sense of control and autonomy.\n",
       "\n",
       "The predicted Happiness Score, taking into account these positive changes in socio-economic indicators, was 5.44. However, the actual Happiness Score for 2024 was 4.68, lower than predicted. This discrepancy might suggest that while economic conditions, social support, and freedom improved, other important factors influencing happiness may have been overlooked. These could include variables such as health, perceptions of corruption, generosity, and education. Therefore, while the improved indicators are positive and helpful, they may not cover all aspects required for the overall happiness score to increase as predicted.\n",
       "  \n",
       "It's also important to consider that the impact of these socio-economic changes may not be immediately observed within the same year, as people's perception and experience of their quality of life and happiness might take time to adjust to these improvements. It could potentially reflect in happiness scores in subsequent years. \n",
       "\n",
       "Conclusively, it's crucial for policymakers and social researchers to continue assessing various factors that influence happiness and not only concentrate on economic growth, social support, and freedom, while planning interventions for improving wellbeing and life satisfaction."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"##  Scenario Simulation: Ukraine 2024\\n\"))\n",
    "display(Markdown(f\"**- Predicted Happiness Score (with improvements)**: `{predicted_score:.2f}`\"))\n",
    "display(Markdown(f\"**- Actual Happiness Score (2024)**: `{real_score:.2f}`\"))\n",
    "\n",
    "error = abs(predicted_score - real_score)\n",
    "delta_text = f\"`{error:.2f}` points difference\"\n",
    "display(Markdown(f\"**- Difference**: {delta_text}\"))\n",
    "\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown(\"##  GenAI Explanation:\\n\"))\n",
    "display(Markdown(explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed51cce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# === Simulate individual variable changes separately ===\n",
    "def simulate_single_feature_change(feature, change_value, df, model, scaler, features, window_size):\n",
    "    scenario = df[(df[\"Country\"] == \"Ukraine\") & (df[\"Year\"].isin([2022, 2023, 2024]))].copy()\n",
    "    scenario = scenario.sort_values(\"Year\").reset_index(drop=True)\n",
    "    scenario.loc[scenario[\"Year\"] == 2024, feature] += change_value\n",
    "    X = scenario[features].values.reshape(1, window_size, len(features))\n",
    "    X_scaled = scaler.transform(X.reshape(-1, len(features))).reshape(1, window_size, len(features))\n",
    "    pred = model.predict(X_scaled)[0][0]\n",
    "    return pred\n",
    "\n",
    "\n",
    "actual_score = df[(df[\"Country\"] == \"Ukraine\") & (df[\"Year\"] == 2024)][\"HappinessScore\"].values[0]\n",
    "\n",
    "\n",
    "gdp_score = simulate_single_feature_change(\"GDP\", df.loc[(df[\"Country\"] == \"Ukraine\") & (df[\"Year\"] == 2024), \"GDP\"].values[0] * 0.10, df, model5, scaler, features, window_size)\n",
    "support_score = simulate_single_feature_change(\"SocialSupport\", 0.1, df, model5, scaler, features, window_size)\n",
    "freedom_score = simulate_single_feature_change(\"Freedom\", 0.1, df, model5, scaler, features, window_size)\n",
    "\n",
    "# === GenAI analysis for individual changes ===\n",
    "def genai_explanation_all(gdp_score, support_score, freedom_score, actual_score):\n",
    "    prompt = f\"\"\"\n",
    "Country: Ukraine\n",
    "Year: 2024\n",
    "\n",
    "Three separate scenario-based happiness predictions were made:\n",
    "1. GDP increased by 10% → Predicted Happiness: {gdp_score:.2f}\n",
    "2. Social Support increased by +0.1 → Predicted Happiness: {support_score:.2f}\n",
    "3. Freedom increased by +0.1 → Predicted Happiness: {freedom_score:.2f}\n",
    "\n",
    "Actual Happiness Score in 2024: {actual_score:.2f}\n",
    "\n",
    "Analyze:\n",
    "- Which indicator had the strongest positive effect?\n",
    "- Why might the actual score still be lower than the predicted ones?\n",
    "- What does this imply about the broader determinants of happiness in Ukraine during this period?\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a policy analyst and social researcher.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "explanation = genai_explanation_all(gdp_score, support_score, freedom_score, actual_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecb786ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## 🇺🇦 Scenario-Based Happiness Predictions for **Ukraine (2024)**\n",
       "\n",
       "| Indicator Change                  | Predicted Happiness Score |\n",
       "|----------------------------------|----------------------------|\n",
       "|  GDP ↑ by 10%                  | **5.35**                |\n",
       "|  Social Support ↑ by +0.1     | **5.39**            |\n",
       "|  Freedom ↑ by +0.1             | **5.37**            |\n",
       "\n",
       "### 🟡 Actual Reported Happiness Score (2024): **4.68**\n",
       "\n",
       "---\n",
       "\n",
       "### - **GenAI Explanation**\n",
       "1. The indicator with the strongest positive effect on the predicted happiness in Ukraine in 2024 is the increase in social support, resulting in a predicted happiness score of 5.39. This is based on the given scenarios and the scores that they yielded.\n",
       "\n",
       "2. There could be several reasons why the actual happiness score is still lower than the predicted ones:\n",
       "\n",
       "    - The projections may have neglected other significant factors affecting happiness, such as health, education, corruption perception, job security, and income inequality. Since these areas weren't considered in the three scenarios, their potential adverse impacts might be why the actual score is lower.\n",
       "    \n",
       "    - The relationship between the three areas considered (GDP, social support, and freedom) and happiness may not be as linear or direct as assumed in the predictions. For instance, cultural aspects, societal values, or historical events might modulate the impact of these factors on happiness.\n",
       "\n",
       "    - The predictions could be overestimating the impact of these factors on happiness or could be too simplistic, ignoring potential interactions between these variables.\n",
       "    \n",
       "    - There might have been unforeseen negative events or circumstances in the year 2024 that significantly impacted the economy, social support, or freedom, and thereby the happiness score, which were not factored into the predicted scenarios.\n",
       "\n",
       "3. The gap between the predicted and actual happiness scores suggests that broader socio-economic and sociopolitical determinants play a crucial role in influencing happiness in Ukraine. It signifies that while improving GDP, social support, and freedom are important, these alone are not sufficient to enhance overall happiness. Policies therefore must be holistic and multifaceted, focusing also on improving areas such as health, education, income equality, and tackling corruption. It also implies that understanding cultural, societal, and historical aspects of happiness is essential in making accurate predictions. This should inform future research and policy development in Ukraine. For instance, initiatives to increase financial stability or freedom must be balanced with efforts to improve the social fabric and societal well-being as a whole.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def output(gdp_score, support_score, freedom_score, actual_score, explanation):\n",
    "    md = f\"\"\"\n",
    "## 🇺🇦 Scenario-Based Happiness Predictions for **Ukraine (2024)**\n",
    "\n",
    "| Indicator Change                  | Predicted Happiness Score |\n",
    "|----------------------------------|----------------------------|\n",
    "|  GDP ↑ by 10%                  | **{gdp_score:.2f}**                |\n",
    "|  Social Support ↑ by +0.1     | **{support_score:.2f}**            |\n",
    "|  Freedom ↑ by +0.1             | **{freedom_score:.2f}**            |\n",
    "\n",
    "### 🟡 Actual Reported Happiness Score (2024): **{actual_score:.2f}**\n",
    "\n",
    "---\n",
    "\n",
    "### - **GenAI Explanation**\n",
    "{explanation}\n",
    "\"\"\"\n",
    "    display(Markdown(md))\n",
    "\n",
    "output(gdp_score, support_score, freedom_score, actual_score, explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a25650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "lstm_pred_baseline = float(ukraine_pred5)\n",
    "\n",
    "lstm_pred_gdp = float(gdp_score)\n",
    "lstm_pred_ss = float(support_score)\n",
    "lstm_pred_f = float(freedom_score)\n",
    "\n",
    "lstm_results = {\n",
    "    'model': 'LSTM',\n",
    "    'baseline': lstm_pred_baseline,\n",
    "    'GDP+10%': lstm_pred_gdp,\n",
    "    'SocialSupport+0.1': lstm_pred_ss,\n",
    "    'Freedom+0.1': lstm_pred_f\n",
    "}\n",
    "\n",
    "with open('../model_what_if/lstm_scenarios.json', 'w') as f:\n",
    "    json.dump(lstm_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13936c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model5.save('/HappyLens-NN/dashboard/lstm_model.h5')\n",
    "model5.save('/HappyLens-NN/dashboard/lstm_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
