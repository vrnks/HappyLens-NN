{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8416b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82caa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>HappinessScore</th>\n",
       "      <th>GDP</th>\n",
       "      <th>SocialSupport</th>\n",
       "      <th>LifeExpectancy</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>Finland</td>\n",
       "      <td>7.736</td>\n",
       "      <td>1.7490</td>\n",
       "      <td>1.783000</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>7.521</td>\n",
       "      <td>1.8250</td>\n",
       "      <td>1.748000</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>7.515</td>\n",
       "      <td>1.7990</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>7.345</td>\n",
       "      <td>1.7830</td>\n",
       "      <td>1.698000</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>7.306</td>\n",
       "      <td>1.8220</td>\n",
       "      <td>1.667000</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>2011</td>\n",
       "      <td>152</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>3.678</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>2011</td>\n",
       "      <td>153</td>\n",
       "      <td>Sierra Leone</td>\n",
       "      <td>3.586</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>2011</td>\n",
       "      <td>154</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>3.568</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>2011</td>\n",
       "      <td>155</td>\n",
       "      <td>Benin</td>\n",
       "      <td>3.493</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>2011</td>\n",
       "      <td>156</td>\n",
       "      <td>Togo</td>\n",
       "      <td>3.007</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.182982</td>\n",
       "      <td>0.132473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Rank                   Country  HappinessScore     GDP  \\\n",
       "0     2024     1                   Finland           7.736  1.7490   \n",
       "1     2024     2                   Denmark           7.521  1.8250   \n",
       "2     2024     3                   Iceland           7.515  1.7990   \n",
       "3     2024     4                    Sweden           7.345  1.7830   \n",
       "4     2024     5               Netherlands           7.306  1.8220   \n",
       "...    ...   ...                       ...             ...     ...   \n",
       "1951  2011   152                   Burundi           3.678  0.3674   \n",
       "1952  2011   153              Sierra Leone           3.586  0.3674   \n",
       "1953  2011   154  Central African Republic           3.568  0.3674   \n",
       "1954  2011   155                     Benin           3.493  0.3674   \n",
       "1955  2011   156                      Togo           3.007  0.3674   \n",
       "\n",
       "      SocialSupport  LifeExpectancy   Freedom  Generosity  Corruption  \n",
       "0          1.783000          0.8240  0.986000    0.110000    0.502000  \n",
       "1          1.748000          0.8200  0.955000    0.150000    0.488000  \n",
       "2          1.840000          0.8730  0.971000    0.201000    0.173000  \n",
       "3          1.698000          0.8890  0.952000    0.170000    0.467000  \n",
       "4          1.667000          0.8440  0.860000    0.186000    0.344000  \n",
       "...             ...             ...       ...         ...         ...  \n",
       "1951       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "1952       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "1953       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "1954       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "1955       0.627745          0.3348  0.299345    0.182982    0.132473  \n",
       "\n",
       "[1956 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the World Happiness Report dataset\n",
    "df = pd.read_csv(\"/Users/admin/Desktop/Projects/HappyLens_NN/data/happiness_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89266145",
   "metadata": {},
   "source": [
    "# === Model 1: Basic Dense NN ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e3146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "features = ['GDP', 'SocialSupport', 'LifeExpectancy', 'Freedom', 'Generosity', 'Corruption']\n",
    "target = 'HappinessScore'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d0c052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/Projects/HappyLens_NN/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.6215 - mae: 2.0840 - val_loss: 1.1814 - val_mae: 0.8999\n",
      "Epoch 2/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1221 - mae: 0.8550 - val_loss: 0.8789 - val_mae: 0.7499\n",
      "Epoch 3/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0238 - mae: 0.8048 - val_loss: 0.8939 - val_mae: 0.7681\n",
      "Epoch 4/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9671 - mae: 0.7922 - val_loss: 0.8390 - val_mae: 0.7408\n",
      "Epoch 5/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9817 - mae: 0.7819 - val_loss: 0.8716 - val_mae: 0.7539\n",
      "Epoch 6/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0258 - mae: 0.8071 - val_loss: 0.8877 - val_mae: 0.7239\n",
      "Epoch 7/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9442 - mae: 0.7687 - val_loss: 0.7911 - val_mae: 0.6957\n",
      "Epoch 8/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9151 - mae: 0.7460 - val_loss: 0.8035 - val_mae: 0.7008\n",
      "Epoch 9/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9307 - mae: 0.7555 - val_loss: 0.8221 - val_mae: 0.6908\n",
      "Epoch 10/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0432 - mae: 0.8185 - val_loss: 0.9538 - val_mae: 0.7588\n",
      "Epoch 11/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0109 - mae: 0.7931 - val_loss: 0.8445 - val_mae: 0.7448\n",
      "Epoch 12/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9549 - mae: 0.7738 - val_loss: 0.7639 - val_mae: 0.6864\n",
      "Epoch 13/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9174 - mae: 0.7532 - val_loss: 0.7862 - val_mae: 0.7031\n",
      "Epoch 14/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8678 - mae: 0.7282 - val_loss: 0.7991 - val_mae: 0.7145\n",
      "Epoch 15/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9333 - mae: 0.7705 - val_loss: 0.7433 - val_mae: 0.6636\n",
      "Epoch 16/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9133 - mae: 0.7455 - val_loss: 0.7813 - val_mae: 0.6890\n",
      "Epoch 17/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8942 - mae: 0.7442 - val_loss: 0.7389 - val_mae: 0.6647\n",
      "Epoch 18/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8709 - mae: 0.7190 - val_loss: 0.7721 - val_mae: 0.6780\n",
      "Epoch 19/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9001 - mae: 0.7451 - val_loss: 0.7860 - val_mae: 0.6904\n",
      "Epoch 20/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8738 - mae: 0.7335 - val_loss: 0.8729 - val_mae: 0.7591\n",
      "Epoch 21/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8870 - mae: 0.7361 - val_loss: 0.9284 - val_mae: 0.7328\n",
      "Epoch 22/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8105 - mae: 0.6859 - val_loss: 0.7808 - val_mae: 0.6923\n",
      "Epoch 23/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8775 - mae: 0.7389 - val_loss: 0.8706 - val_mae: 0.7378\n",
      "Epoch 24/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9151 - mae: 0.7428 - val_loss: 0.9481 - val_mae: 0.7652\n",
      "Epoch 25/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8872 - mae: 0.7497 - val_loss: 0.7533 - val_mae: 0.6682\n",
      "Epoch 26/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9526 - mae: 0.7544 - val_loss: 0.8185 - val_mae: 0.6867\n",
      "Epoch 27/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9194 - mae: 0.7482 - val_loss: 0.7724 - val_mae: 0.6890\n",
      "Epoch 28/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8639 - mae: 0.7254 - val_loss: 0.8012 - val_mae: 0.6774\n",
      "Epoch 29/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9347 - mae: 0.7559 - val_loss: 0.7530 - val_mae: 0.6764\n",
      "Epoch 30/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9452 - mae: 0.7618 - val_loss: 0.8220 - val_mae: 0.7185\n",
      "Epoch 31/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8808 - mae: 0.7280 - val_loss: 0.7773 - val_mae: 0.6859\n",
      "Epoch 32/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8279 - mae: 0.7019 - val_loss: 0.7333 - val_mae: 0.6600\n",
      "Epoch 33/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9638 - mae: 0.7554 - val_loss: 0.7417 - val_mae: 0.6698\n",
      "Epoch 34/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8548 - mae: 0.7086 - val_loss: 0.7316 - val_mae: 0.6581\n",
      "Epoch 35/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8546 - mae: 0.7013 - val_loss: 0.7281 - val_mae: 0.6579\n",
      "Epoch 36/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8074 - mae: 0.6743 - val_loss: 0.7548 - val_mae: 0.6764\n",
      "Epoch 37/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8726 - mae: 0.7206 - val_loss: 0.7577 - val_mae: 0.6768\n",
      "Epoch 38/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8163 - mae: 0.6900 - val_loss: 0.7494 - val_mae: 0.6669\n",
      "Epoch 39/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8222 - mae: 0.6945 - val_loss: 0.7436 - val_mae: 0.6596\n",
      "Epoch 40/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8598 - mae: 0.7026 - val_loss: 0.8669 - val_mae: 0.7285\n",
      "Epoch 41/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8648 - mae: 0.7130 - val_loss: 0.7944 - val_mae: 0.6982\n",
      "Epoch 42/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8408 - mae: 0.7053 - val_loss: 0.7584 - val_mae: 0.6827\n",
      "Epoch 43/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8472 - mae: 0.7142 - val_loss: 0.8840 - val_mae: 0.7199\n",
      "Epoch 44/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8946 - mae: 0.7261 - val_loss: 0.8149 - val_mae: 0.7105\n",
      "Epoch 45/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8824 - mae: 0.7286 - val_loss: 0.7383 - val_mae: 0.6612\n",
      "Epoch 46/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8664 - mae: 0.7103 - val_loss: 0.9169 - val_mae: 0.7803\n",
      "Epoch 47/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9025 - mae: 0.7500 - val_loss: 0.7721 - val_mae: 0.6770\n",
      "Epoch 48/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8585 - mae: 0.7043 - val_loss: 0.7410 - val_mae: 0.6672\n",
      "Epoch 49/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8180 - mae: 0.6879 - val_loss: 0.7282 - val_mae: 0.6565\n",
      "Epoch 50/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8347 - mae: 0.6926 - val_loss: 0.7502 - val_mae: 0.6729\n",
      "Epoch 51/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8294 - mae: 0.6914 - val_loss: 0.9844 - val_mae: 0.8270\n",
      "Epoch 52/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8971 - mae: 0.7434 - val_loss: 0.7535 - val_mae: 0.6698\n",
      "Epoch 53/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8328 - mae: 0.6898 - val_loss: 0.7248 - val_mae: 0.6536\n",
      "Epoch 54/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8311 - mae: 0.7036 - val_loss: 0.7458 - val_mae: 0.6629\n",
      "Epoch 55/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8270 - mae: 0.6957 - val_loss: 0.8182 - val_mae: 0.7288\n",
      "Epoch 56/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8975 - mae: 0.7422 - val_loss: 0.7420 - val_mae: 0.6691\n",
      "Epoch 57/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8031 - mae: 0.6806 - val_loss: 0.7373 - val_mae: 0.6642\n",
      "Epoch 58/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8923 - mae: 0.7111 - val_loss: 0.7552 - val_mae: 0.6762\n",
      "Epoch 59/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7598 - mae: 0.6630 - val_loss: 0.7256 - val_mae: 0.6528\n",
      "Epoch 60/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7923 - mae: 0.6762 - val_loss: 0.7586 - val_mae: 0.6710\n",
      "Epoch 61/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8626 - mae: 0.7053 - val_loss: 0.8011 - val_mae: 0.7100\n",
      "Epoch 62/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8620 - mae: 0.7041 - val_loss: 0.7318 - val_mae: 0.6602\n",
      "Epoch 63/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8323 - mae: 0.6871 - val_loss: 0.7745 - val_mae: 0.6992\n",
      "Epoch 64/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7743 - mae: 0.6587 - val_loss: 0.7617 - val_mae: 0.6883\n",
      "Epoch 65/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8078 - mae: 0.6796 - val_loss: 0.7420 - val_mae: 0.6642\n",
      "Epoch 66/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8128 - mae: 0.6842 - val_loss: 0.7467 - val_mae: 0.6665\n",
      "Epoch 67/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7668 - mae: 0.6529 - val_loss: 0.7312 - val_mae: 0.6582\n",
      "Epoch 68/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8456 - mae: 0.6945 - val_loss: 0.8579 - val_mae: 0.7405\n",
      "Epoch 69/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8883 - mae: 0.7159 - val_loss: 0.7712 - val_mae: 0.6883\n",
      "Epoch 70/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7972 - mae: 0.6780 - val_loss: 0.8042 - val_mae: 0.6980\n",
      "Epoch 71/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8353 - mae: 0.7003 - val_loss: 0.7834 - val_mae: 0.6943\n",
      "Epoch 72/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8029 - mae: 0.6844 - val_loss: 0.8059 - val_mae: 0.6959\n",
      "Epoch 73/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8517 - mae: 0.6966 - val_loss: 0.7620 - val_mae: 0.6693\n",
      "Epoch 74/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8268 - mae: 0.6918 - val_loss: 0.7684 - val_mae: 0.6687\n",
      "Epoch 75/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8198 - mae: 0.6869 - val_loss: 0.7659 - val_mae: 0.6767\n",
      "Epoch 76/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8330 - mae: 0.6857 - val_loss: 0.7683 - val_mae: 0.6805\n",
      "Epoch 77/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8389 - mae: 0.6961 - val_loss: 0.7514 - val_mae: 0.6686\n",
      "Epoch 78/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7932 - mae: 0.6791 - val_loss: 0.7268 - val_mae: 0.6520\n",
      "Epoch 79/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7985 - mae: 0.6712 - val_loss: 0.7460 - val_mae: 0.6724\n",
      "Epoch 80/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7825 - mae: 0.6656 - val_loss: 0.7674 - val_mae: 0.6743\n",
      "Epoch 81/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8326 - mae: 0.6845 - val_loss: 0.7517 - val_mae: 0.6811\n",
      "Epoch 82/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7645 - mae: 0.6618 - val_loss: 0.8067 - val_mae: 0.6909\n",
      "Epoch 83/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8128 - mae: 0.6828 - val_loss: 0.7482 - val_mae: 0.6727\n",
      "Epoch 84/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7982 - mae: 0.6718 - val_loss: 0.7357 - val_mae: 0.6616\n",
      "Epoch 85/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8042 - mae: 0.6770 - val_loss: 0.7541 - val_mae: 0.6724\n",
      "Epoch 86/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7686 - mae: 0.6596 - val_loss: 0.7631 - val_mae: 0.6841\n",
      "Epoch 87/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8266 - mae: 0.6838 - val_loss: 0.8374 - val_mae: 0.7322\n",
      "Epoch 88/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8266 - mae: 0.6983 - val_loss: 0.7740 - val_mae: 0.6754\n",
      "Epoch 89/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7962 - mae: 0.6679 - val_loss: 0.8086 - val_mae: 0.7061\n",
      "Epoch 90/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8388 - mae: 0.6939 - val_loss: 0.7307 - val_mae: 0.6590\n",
      "Epoch 91/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7578 - mae: 0.6539 - val_loss: 0.7685 - val_mae: 0.6873\n",
      "Epoch 92/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7804 - mae: 0.6606 - val_loss: 0.7643 - val_mae: 0.6844\n",
      "Epoch 93/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8040 - mae: 0.6721 - val_loss: 0.7565 - val_mae: 0.6785\n",
      "Epoch 94/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8192 - mae: 0.6807 - val_loss: 0.7834 - val_mae: 0.6834\n",
      "Epoch 95/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8195 - mae: 0.6894 - val_loss: 0.7719 - val_mae: 0.6908\n",
      "Epoch 96/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8719 - mae: 0.7073 - val_loss: 0.7871 - val_mae: 0.6852\n",
      "Epoch 97/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8346 - mae: 0.6768 - val_loss: 0.8022 - val_mae: 0.6915\n",
      "Epoch 98/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7885 - mae: 0.6739 - val_loss: 0.7483 - val_mae: 0.6668\n",
      "Epoch 99/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8145 - mae: 0.6683 - val_loss: 0.7875 - val_mae: 0.6905\n",
      "Epoch 100/100\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7925 - mae: 0.6537 - val_loss: 0.8264 - val_mae: 0.7044\n"
     ]
    }
   ],
   "source": [
    "# Build a simple feedforward neural network\n",
    "model1 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model1.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "# Train the model\n",
    "history = model1.fit(X_train, y_train, epochs=100, batch_size=16,\n",
    "                    validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ee4450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.8531, MAE: 0.7002\n",
      "Validation MSE: 0.8264, MAE: 0.7044\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "train_mse1, train_mae1 = model1.evaluate(X_train, y_train, verbose=0)\n",
    "val_mse1, val_mae1 = model1.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print(f\"Training MSE: {train_mse1:.4f}, MAE: {train_mae1:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse1:.4f}, MAE: {val_mae1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91d50c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Neural Network Predicted Happiness Score for Ukraine (2024): 5.243\n",
      "Actual Happiness Score: 4.68\n"
     ]
    }
   ],
   "source": [
    "# Make prediction for Ukraine 2024\n",
    "ukraine_2024 = df[(df['Country'] == 'Ukraine') & (df['Year'] == 2024)]\n",
    "X_ukraine = ukraine_2024[features]\n",
    "X_ukraine_scaled = scaler.transform(X_ukraine)\n",
    "\n",
    "ukraine_pred1 = model1.predict(X_ukraine_scaled)[0][0]\n",
    "print(f\"Neural Network Predicted Happiness Score for Ukraine (2024): {ukraine_pred1:.3f}\")\n",
    "\n",
    "real = ukraine_2024['HappinessScore'].values[0]\n",
    "print(f\"Actual Happiness Score: {real}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9341f9",
   "metadata": {},
   "source": [
    "### Model 1: Basic NN\n",
    "- ***Logic***: The simplest model — a basic feedforward neural network with two hidden layers. Only main features are used: GDP, SocialSupport, LifeExpectancy, Freedom, Generosity, Corruption.\n",
    "- ***Goal***: Get a baseline performance without additional complexities.\n",
    "- ***Result***:\n",
    "Val MAE: 0.704,\n",
    "Ukraine error: 0.563\n",
    "- ***Conclusion***: The model behaves stably, though slightly overfits (Train MAE < Val MAE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b2edc",
   "metadata": {},
   "source": [
    "# === Model 2: Deeper Dense NN with Dropout and EarlyStopping ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ffd4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Input(shape=(len(features),)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2ae3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 23.0534 - mae: 4.5232 - val_loss: 1.8077 - val_mae: 1.0971\n",
      "Epoch 2/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0602 - mae: 1.3422 - val_loss: 2.1140 - val_mae: 1.2081\n",
      "Epoch 3/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7009 - mae: 1.2643 - val_loss: 1.4328 - val_mae: 0.9886\n",
      "Epoch 4/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3667 - mae: 1.1961 - val_loss: 1.4081 - val_mae: 0.9809\n",
      "Epoch 5/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3507 - mae: 1.2003 - val_loss: 1.3961 - val_mae: 0.9789\n",
      "Epoch 6/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8948 - mae: 1.1131 - val_loss: 1.1841 - val_mae: 0.9007\n",
      "Epoch 7/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8481 - mae: 1.0764 - val_loss: 1.1379 - val_mae: 0.8830\n",
      "Epoch 8/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8562 - mae: 1.0852 - val_loss: 1.1395 - val_mae: 0.8803\n",
      "Epoch 9/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5740 - mae: 1.0052 - val_loss: 1.1963 - val_mae: 0.9075\n",
      "Epoch 10/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5936 - mae: 0.9983 - val_loss: 0.8800 - val_mae: 0.7586\n",
      "Epoch 11/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5288 - mae: 0.9929 - val_loss: 0.9740 - val_mae: 0.7953\n",
      "Epoch 12/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4697 - mae: 0.9738 - val_loss: 0.9890 - val_mae: 0.8132\n",
      "Epoch 13/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4035 - mae: 0.9457 - val_loss: 0.8947 - val_mae: 0.7624\n",
      "Epoch 14/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4688 - mae: 0.9714 - val_loss: 0.8971 - val_mae: 0.7658\n",
      "Epoch 15/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4664 - mae: 0.9664 - val_loss: 0.8580 - val_mae: 0.7396\n",
      "Epoch 16/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3656 - mae: 0.9334 - val_loss: 0.7967 - val_mae: 0.7019\n",
      "Epoch 17/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3360 - mae: 0.9341 - val_loss: 0.8754 - val_mae: 0.7383\n",
      "Epoch 18/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2646 - mae: 0.8960 - val_loss: 0.8526 - val_mae: 0.7417\n",
      "Epoch 19/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3407 - mae: 0.9323 - val_loss: 0.9385 - val_mae: 0.8014\n",
      "Epoch 20/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2406 - mae: 0.8937 - val_loss: 0.9414 - val_mae: 0.7915\n",
      "Epoch 21/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2368 - mae: 0.8654 - val_loss: 0.8077 - val_mae: 0.7220\n",
      "Epoch 22/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1926 - mae: 0.8713 - val_loss: 0.8402 - val_mae: 0.7432\n",
      "Epoch 23/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1642 - mae: 0.8697 - val_loss: 0.8409 - val_mae: 0.7399\n",
      "Epoch 24/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2380 - mae: 0.8864 - val_loss: 1.0474 - val_mae: 0.8560\n",
      "Epoch 25/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1132 - mae: 0.8437 - val_loss: 0.9571 - val_mae: 0.8084\n",
      "Epoch 26/200\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1448 - mae: 0.8591 - val_loss: 1.0490 - val_mae: 0.8605\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# Train the model with early stopping\n",
    "history = model2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "# Evaluate performance\n",
    "train_mse2, train_mae2 = model2.evaluate(X_train, y_train, verbose=0)\n",
    "val_mse2, val_mae2 = model2.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73f08a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Train MSE: 0.9028, MAE: 0.7467\n",
      "Validation MSE: 0.7967, MAE: 0.7019\n",
      "Neural Network Prediction for Ukraine (2024): 5.670\n",
      "Actual Happiness Score for Ukraine (2024): 4.68\n"
     ]
    }
   ],
   "source": [
    "ukraine_2024 = df[(df['Country'] == 'Ukraine') & (df['Year'] == 2024)]\n",
    "ukraine_input_scaled = scaler.transform(ukraine_2024[features])\n",
    "ukraine_pred2 = model2.predict(ukraine_input_scaled)[0][0]\n",
    "actual_ukraine = ukraine_2024[target].values[0]\n",
    "\n",
    "print(f\"Train MSE: {train_mse2:.4f}, MAE: {train_mae2:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse2:.4f}, MAE: {val_mae2:.4f}\")\n",
    "print(f\"Neural Network Prediction for Ukraine (2024): {ukraine_pred2:.3f}\")\n",
    "print(f\"Actual Happiness Score for Ukraine (2024): {actual_ukraine}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16a611",
   "metadata": {},
   "source": [
    "### Model 2: Deeper NN + Dropout\n",
    "- ***Logic***: The model is deeper (more layers), with added Dropout to combat overfitting and EarlyStopping.\n",
    "- ***Goal***: Reduce overfitting and improve generalization.\n",
    "- ***Result***:\n",
    "Slight improvement in Val MAE: 0.702 (only marginal),\n",
    "Ukraine prediction worse — Abs Error: 0.99\n",
    "- ***Conclusion***: A deeper model doesn’t guarantee better results, possibly due to limited data or the model being too complex.\n",
    "- ***Possible Issue***: The model does not take into account the context of time — it is unaware that in 2024 Ukraine is at war. Economic and social indicators might look better on paper than the actual subjective happiness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3191f3",
   "metadata": {},
   "source": [
    "# === Model 3: Add 'Year' as feature ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85038857",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Year', 'GDP', 'SocialSupport', 'LifeExpectancy', 'Freedom', 'Generosity', 'Corruption']\n",
    "target = 'HappinessScore'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab2b6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model3.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85848418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 23.8108 - mae: 4.7203 - val_loss: 12.2146 - val_mae: 3.2646\n",
      "Epoch 2/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8594 - mae: 2.6510 - val_loss: 2.6407 - val_mae: 1.3202\n",
      "Epoch 3/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2758 - mae: 1.1578 - val_loss: 1.6406 - val_mae: 1.0735\n",
      "Epoch 4/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8736 - mae: 1.0229 - val_loss: 1.5514 - val_mae: 1.0385\n",
      "Epoch 5/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1115 - mae: 1.0848 - val_loss: 1.4926 - val_mae: 1.0260\n",
      "Epoch 6/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8418 - mae: 1.0275 - val_loss: 1.4284 - val_mae: 1.0024\n",
      "Epoch 7/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6616 - mae: 0.9853 - val_loss: 1.3738 - val_mae: 0.9793\n",
      "Epoch 8/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7867 - mae: 0.9904 - val_loss: 1.3134 - val_mae: 0.9561\n",
      "Epoch 9/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6179 - mae: 0.9872 - val_loss: 1.2526 - val_mae: 0.9351\n",
      "Epoch 10/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4625 - mae: 0.9400 - val_loss: 1.1985 - val_mae: 0.9106\n",
      "Epoch 11/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4212 - mae: 0.9080 - val_loss: 1.1587 - val_mae: 0.8910\n",
      "Epoch 12/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3292 - mae: 0.8931 - val_loss: 1.1323 - val_mae: 0.8819\n",
      "Epoch 13/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2477 - mae: 0.8763 - val_loss: 1.1170 - val_mae: 0.8764\n",
      "Epoch 14/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2331 - mae: 0.8695 - val_loss: 1.0817 - val_mae: 0.8624\n",
      "Epoch 15/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2443 - mae: 0.8743 - val_loss: 1.0437 - val_mae: 0.8451\n",
      "Epoch 16/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1672 - mae: 0.8533 - val_loss: 1.0159 - val_mae: 0.8286\n",
      "Epoch 17/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1469 - mae: 0.8509 - val_loss: 0.9875 - val_mae: 0.8116\n",
      "Epoch 18/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1353 - mae: 0.8573 - val_loss: 0.9773 - val_mae: 0.8107\n",
      "Epoch 19/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0863 - mae: 0.8338 - val_loss: 0.9498 - val_mae: 0.7926\n",
      "Epoch 20/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0691 - mae: 0.8272 - val_loss: 0.9571 - val_mae: 0.7942\n",
      "Epoch 21/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0447 - mae: 0.8119 - val_loss: 0.9257 - val_mae: 0.7786\n",
      "Epoch 22/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9627 - mae: 0.7789 - val_loss: 0.9121 - val_mae: 0.7750\n",
      "Epoch 23/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0049 - mae: 0.7929 - val_loss: 0.9049 - val_mae: 0.7678\n",
      "Epoch 24/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9707 - mae: 0.7799 - val_loss: 0.8907 - val_mae: 0.7605\n",
      "Epoch 25/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9849 - mae: 0.7858 - val_loss: 0.8799 - val_mae: 0.7514\n",
      "Epoch 26/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9362 - mae: 0.7633 - val_loss: 0.8715 - val_mae: 0.7485\n",
      "Epoch 27/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9524 - mae: 0.7739 - val_loss: 0.8588 - val_mae: 0.7401\n",
      "Epoch 28/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9340 - mae: 0.7692 - val_loss: 0.8581 - val_mae: 0.7390\n",
      "Epoch 29/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9285 - mae: 0.7572 - val_loss: 0.8414 - val_mae: 0.7325\n",
      "Epoch 30/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9121 - mae: 0.7523 - val_loss: 0.8422 - val_mae: 0.7311\n",
      "Epoch 31/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9025 - mae: 0.7484 - val_loss: 0.8319 - val_mae: 0.7255\n",
      "Epoch 32/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8932 - mae: 0.7395 - val_loss: 0.8350 - val_mae: 0.7228\n",
      "Epoch 33/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9055 - mae: 0.7474 - val_loss: 0.8091 - val_mae: 0.7081\n",
      "Epoch 34/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8865 - mae: 0.7346 - val_loss: 0.8165 - val_mae: 0.7138\n",
      "Epoch 35/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8873 - mae: 0.7406 - val_loss: 0.8105 - val_mae: 0.7095\n",
      "Epoch 36/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8843 - mae: 0.7396 - val_loss: 0.8300 - val_mae: 0.7179\n",
      "Epoch 37/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9060 - mae: 0.7471 - val_loss: 0.8380 - val_mae: 0.7169\n",
      "Epoch 38/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8638 - mae: 0.7202 - val_loss: 0.7949 - val_mae: 0.6989\n",
      "Epoch 39/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9125 - mae: 0.7526 - val_loss: 0.8063 - val_mae: 0.7023\n",
      "Epoch 40/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9006 - mae: 0.7417 - val_loss: 0.7907 - val_mae: 0.6956\n",
      "Epoch 41/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8525 - mae: 0.7167 - val_loss: 0.8220 - val_mae: 0.7075\n",
      "Epoch 42/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9133 - mae: 0.7566 - val_loss: 0.7993 - val_mae: 0.6959\n",
      "Epoch 43/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9019 - mae: 0.7355 - val_loss: 0.7869 - val_mae: 0.6884\n",
      "Epoch 44/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8921 - mae: 0.7346 - val_loss: 0.7916 - val_mae: 0.6897\n",
      "Epoch 45/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8507 - mae: 0.7105 - val_loss: 0.7789 - val_mae: 0.6855\n",
      "Epoch 46/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8439 - mae: 0.7172 - val_loss: 0.7765 - val_mae: 0.6833\n",
      "Epoch 47/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8766 - mae: 0.7309 - val_loss: 0.7837 - val_mae: 0.6898\n",
      "Epoch 48/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8424 - mae: 0.7098 - val_loss: 0.7779 - val_mae: 0.6837\n",
      "Epoch 49/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8274 - mae: 0.7053 - val_loss: 0.7698 - val_mae: 0.6785\n",
      "Epoch 50/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8450 - mae: 0.7083 - val_loss: 0.7894 - val_mae: 0.6874\n",
      "Epoch 51/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8010 - mae: 0.6888 - val_loss: 0.7759 - val_mae: 0.6813\n",
      "Epoch 52/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8472 - mae: 0.7169 - val_loss: 0.7662 - val_mae: 0.6772\n",
      "Epoch 53/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8557 - mae: 0.7148 - val_loss: 0.8285 - val_mae: 0.7010\n",
      "Epoch 54/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8714 - mae: 0.7186 - val_loss: 0.7577 - val_mae: 0.6691\n",
      "Epoch 55/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8001 - mae: 0.6831 - val_loss: 0.7645 - val_mae: 0.6750\n",
      "Epoch 56/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8462 - mae: 0.7113 - val_loss: 0.7679 - val_mae: 0.6734\n",
      "Epoch 57/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8572 - mae: 0.7110 - val_loss: 0.7644 - val_mae: 0.6724\n",
      "Epoch 58/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8385 - mae: 0.7049 - val_loss: 0.7904 - val_mae: 0.6793\n",
      "Epoch 59/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7689 - mae: 0.6703 - val_loss: 0.7570 - val_mae: 0.6677\n",
      "Epoch 60/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8298 - mae: 0.7065 - val_loss: 0.7617 - val_mae: 0.6703\n",
      "Epoch 61/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7964 - mae: 0.6790 - val_loss: 0.7609 - val_mae: 0.6694\n",
      "Epoch 62/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7906 - mae: 0.6774 - val_loss: 0.7566 - val_mae: 0.6677\n",
      "Epoch 63/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7843 - mae: 0.6763 - val_loss: 0.7620 - val_mae: 0.6671\n",
      "Epoch 64/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8212 - mae: 0.6958 - val_loss: 0.7643 - val_mae: 0.6701\n",
      "Epoch 65/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8429 - mae: 0.6973 - val_loss: 0.7599 - val_mae: 0.6707\n",
      "Epoch 66/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8281 - mae: 0.6994 - val_loss: 0.7634 - val_mae: 0.6696\n",
      "Epoch 67/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7923 - mae: 0.6840 - val_loss: 0.7576 - val_mae: 0.6701\n",
      "Epoch 68/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7615 - mae: 0.6670 - val_loss: 0.7562 - val_mae: 0.6676\n",
      "Epoch 69/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7995 - mae: 0.6826 - val_loss: 0.7625 - val_mae: 0.6699\n",
      "Epoch 70/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8111 - mae: 0.6840 - val_loss: 0.7596 - val_mae: 0.6729\n",
      "Epoch 71/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8406 - mae: 0.6937 - val_loss: 0.7541 - val_mae: 0.6674\n",
      "Epoch 72/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7972 - mae: 0.6852 - val_loss: 0.7772 - val_mae: 0.6809\n",
      "Epoch 73/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7707 - mae: 0.6681 - val_loss: 0.7547 - val_mae: 0.6663\n",
      "Epoch 74/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8122 - mae: 0.6812 - val_loss: 0.7563 - val_mae: 0.6694\n",
      "Epoch 75/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8008 - mae: 0.6774 - val_loss: 0.7659 - val_mae: 0.6703\n",
      "Epoch 76/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8151 - mae: 0.6848 - val_loss: 0.7579 - val_mae: 0.6688\n",
      "Epoch 77/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8381 - mae: 0.7012 - val_loss: 0.7536 - val_mae: 0.6641\n",
      "Epoch 78/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8663 - mae: 0.7189 - val_loss: 0.7603 - val_mae: 0.6689\n",
      "Epoch 79/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8316 - mae: 0.6906 - val_loss: 0.7513 - val_mae: 0.6626\n",
      "Epoch 80/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8110 - mae: 0.7012 - val_loss: 0.7700 - val_mae: 0.6720\n",
      "Epoch 81/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7971 - mae: 0.6789 - val_loss: 0.7584 - val_mae: 0.6677\n",
      "Epoch 82/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8562 - mae: 0.7129 - val_loss: 0.7574 - val_mae: 0.6687\n",
      "Epoch 83/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8094 - mae: 0.6900 - val_loss: 0.7545 - val_mae: 0.6686\n",
      "Epoch 84/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8307 - mae: 0.6947 - val_loss: 0.7523 - val_mae: 0.6633\n",
      "Epoch 85/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8283 - mae: 0.6915 - val_loss: 0.7573 - val_mae: 0.6696\n",
      "Epoch 86/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8142 - mae: 0.6978 - val_loss: 0.7606 - val_mae: 0.6697\n",
      "Epoch 87/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8624 - mae: 0.7107 - val_loss: 0.8083 - val_mae: 0.7007\n",
      "Epoch 88/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8460 - mae: 0.7069 - val_loss: 0.7580 - val_mae: 0.6664\n",
      "Epoch 89/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7733 - mae: 0.6711 - val_loss: 0.7546 - val_mae: 0.6678\n",
      "Epoch 90/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7739 - mae: 0.6682 - val_loss: 0.7602 - val_mae: 0.6667\n",
      "Epoch 91/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8232 - mae: 0.6941 - val_loss: 0.7544 - val_mae: 0.6677\n",
      "Epoch 92/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8168 - mae: 0.6899 - val_loss: 0.7902 - val_mae: 0.6819\n",
      "Epoch 93/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8343 - mae: 0.6946 - val_loss: 0.7620 - val_mae: 0.6740\n",
      "Epoch 94/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8010 - mae: 0.6815 - val_loss: 0.7522 - val_mae: 0.6666\n",
      "Epoch 95/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7906 - mae: 0.6754 - val_loss: 0.7640 - val_mae: 0.6767\n",
      "Epoch 96/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7786 - mae: 0.6671 - val_loss: 0.7586 - val_mae: 0.6670\n",
      "Epoch 97/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8076 - mae: 0.6842 - val_loss: 0.7621 - val_mae: 0.6702\n",
      "Epoch 98/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7828 - mae: 0.6733 - val_loss: 0.7651 - val_mae: 0.6711\n",
      "Epoch 99/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7967 - mae: 0.6812 - val_loss: 0.7579 - val_mae: 0.6722\n",
      "Epoch 100/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7789 - mae: 0.6646 - val_loss: 0.7907 - val_mae: 0.6802\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100, batch_size=32, verbose=1\n",
    ")\n",
    "\n",
    "train_mse3, train_mae3 = model3.evaluate(X_train, y_train, verbose=0)\n",
    "val_mse3, val_mae3 = model3.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d3d6275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.8201, MAE: 0.6802\n",
      "Validation MSE: 0.7907, MAE: 0.6802\n",
      "Prediction for Ukraine (2024): 5.537\n",
      "Actual Score: 4.68\n"
     ]
    }
   ],
   "source": [
    "# Прогноз для України 2024\n",
    "ukraine_2024 = df[(df[\"Year\"] == 2024) & (df[\"Country\"] == \"Ukraine\")]\n",
    "ukraine_features = scaler.transform(ukraine_2024[features])\n",
    "ukraine_pred3 = model3.predict(ukraine_features, verbose=0)[0][0]\n",
    "ukraine_actual = ukraine_2024[\"HappinessScore\"].values[0]\n",
    "\n",
    "# Вивід результатів\n",
    "print(f\"Train MSE: {train_mse3:.4f}, MAE: {train_mae3:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse3:.4f}, MAE: {val_mae3:.4f}\")\n",
    "print(f\"Prediction for Ukraine (2024): {ukraine_pred3:.3f}\")\n",
    "print(f\"Actual Score: {ukraine_actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a26d85",
   "metadata": {},
   "source": [
    "### Model 3: + Year\n",
    "- ***Logic***: Added Year as a feature to capture time dynamics (economic, social changes, etc.).\n",
    "- ***Goal***: Allow the model to “see” temporal trends without LSTM.\n",
    "- ***Result***:\n",
    "Lowest Train MAE among NN models: 0.680,\n",
    "But Ukraine prediction did not improve (Abs Error: 0.857)\n",
    "- ***Conclusion***: Adding year slightly improves overall quality but does not help with country-specific accuracy. The model may have generalized more over time but lost local precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e054ae2",
   "metadata": {},
   "source": [
    "# === Model 4: Stratified split by year group ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b740b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year_cat'] = pd.cut(df['Year'], bins=[2010,2015,2018,2020,2022,2024], labels=False)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, val_index in split.split(df, df['year_cat']):\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[val_index]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_df[features])\n",
    "y_train = train_df[target].values\n",
    "X_val = scaler.transform(val_df[features])\n",
    "y_val = val_df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33506586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Побудова моделі (зменшена глибина та кількість нейронів)\n",
    "model4 = keras.Sequential([\n",
    "    layers.Input(shape=(len(features),)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model4.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b42892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 26.8755 - mae: 5.0696 - val_loss: 23.4823 - val_mae: 4.6887\n",
      "Epoch 2/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.5247 - mae: 4.3375 - val_loss: 15.3133 - val_mae: 3.5952\n",
      "Epoch 3/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.1497 - mae: 3.1204 - val_loss: 6.5184 - val_mae: 2.1617\n",
      "Epoch 4/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8996 - mae: 1.8245 - val_loss: 2.3878 - val_mae: 1.2344\n",
      "Epoch 5/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0835 - mae: 1.1377 - val_loss: 1.8670 - val_mae: 1.1059\n",
      "Epoch 6/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0239 - mae: 1.0876 - val_loss: 1.7643 - val_mae: 1.0798\n",
      "Epoch 7/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8192 - mae: 1.0592 - val_loss: 1.6851 - val_mae: 1.0530\n",
      "Epoch 8/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8489 - mae: 1.0503 - val_loss: 1.6242 - val_mae: 1.0354\n",
      "Epoch 9/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7377 - mae: 1.0183 - val_loss: 1.5580 - val_mae: 1.0117\n",
      "Epoch 10/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6102 - mae: 0.9970 - val_loss: 1.5166 - val_mae: 0.9968\n",
      "Epoch 11/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5369 - mae: 0.9903 - val_loss: 1.4716 - val_mae: 0.9801\n",
      "Epoch 12/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5027 - mae: 0.9657 - val_loss: 1.4449 - val_mae: 0.9711\n",
      "Epoch 13/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3344 - mae: 0.9232 - val_loss: 1.3790 - val_mae: 0.9494\n",
      "Epoch 14/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5155 - mae: 0.9551 - val_loss: 1.3290 - val_mae: 0.9302\n",
      "Epoch 15/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4273 - mae: 0.9484 - val_loss: 1.2990 - val_mae: 0.9177\n",
      "Epoch 16/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3901 - mae: 0.9091 - val_loss: 1.2724 - val_mae: 0.9032\n",
      "Epoch 17/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3838 - mae: 0.9265 - val_loss: 1.2263 - val_mae: 0.8912\n",
      "Epoch 18/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1982 - mae: 0.8792 - val_loss: 1.2030 - val_mae: 0.8802\n",
      "Epoch 19/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1818 - mae: 0.8619 - val_loss: 1.1629 - val_mae: 0.8653\n",
      "Epoch 20/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2920 - mae: 0.8927 - val_loss: 1.1440 - val_mae: 0.8589\n",
      "Epoch 21/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2084 - mae: 0.8750 - val_loss: 1.1524 - val_mae: 0.8549\n",
      "Epoch 22/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1767 - mae: 0.8564 - val_loss: 1.1074 - val_mae: 0.8366\n",
      "Epoch 23/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1173 - mae: 0.8484 - val_loss: 1.1109 - val_mae: 0.8354\n",
      "Epoch 24/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0848 - mae: 0.8320 - val_loss: 1.0709 - val_mae: 0.8268\n",
      "Epoch 25/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0468 - mae: 0.8182 - val_loss: 1.0660 - val_mae: 0.8225\n",
      "Epoch 26/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0565 - mae: 0.8102 - val_loss: 1.0282 - val_mae: 0.8091\n",
      "Epoch 27/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9897 - mae: 0.7810 - val_loss: 1.0314 - val_mae: 0.8035\n",
      "Epoch 28/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9765 - mae: 0.7894 - val_loss: 1.0125 - val_mae: 0.7977\n",
      "Epoch 29/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0338 - mae: 0.8120 - val_loss: 0.9852 - val_mae: 0.7846\n",
      "Epoch 30/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9732 - mae: 0.7895 - val_loss: 0.9756 - val_mae: 0.7833\n",
      "Epoch 31/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9812 - mae: 0.7936 - val_loss: 0.9641 - val_mae: 0.7769\n",
      "Epoch 32/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9378 - mae: 0.7805 - val_loss: 0.9621 - val_mae: 0.7730\n",
      "Epoch 33/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9205 - mae: 0.7652 - val_loss: 0.9576 - val_mae: 0.7744\n",
      "Epoch 34/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9645 - mae: 0.7913 - val_loss: 0.9694 - val_mae: 0.7713\n",
      "Epoch 35/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8789 - mae: 0.7469 - val_loss: 0.9420 - val_mae: 0.7606\n",
      "Epoch 36/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8964 - mae: 0.7573 - val_loss: 0.9373 - val_mae: 0.7572\n",
      "Epoch 37/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8765 - mae: 0.7392 - val_loss: 0.9343 - val_mae: 0.7587\n",
      "Epoch 38/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8893 - mae: 0.7537 - val_loss: 0.9168 - val_mae: 0.7515\n",
      "Epoch 39/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9039 - mae: 0.7553 - val_loss: 0.9163 - val_mae: 0.7496\n",
      "Epoch 40/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8734 - mae: 0.7345 - val_loss: 0.9112 - val_mae: 0.7479\n",
      "Epoch 41/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8995 - mae: 0.7507 - val_loss: 0.9253 - val_mae: 0.7501\n",
      "Epoch 42/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8808 - mae: 0.7412 - val_loss: 0.9040 - val_mae: 0.7447\n",
      "Epoch 43/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8620 - mae: 0.7343 - val_loss: 0.8991 - val_mae: 0.7402\n",
      "Epoch 44/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9181 - mae: 0.7556 - val_loss: 0.8979 - val_mae: 0.7421\n",
      "Epoch 45/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9138 - mae: 0.7566 - val_loss: 0.8902 - val_mae: 0.7364\n",
      "Epoch 46/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8676 - mae: 0.7325 - val_loss: 0.9076 - val_mae: 0.7362\n",
      "Epoch 47/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8347 - mae: 0.7194 - val_loss: 0.8842 - val_mae: 0.7329\n",
      "Epoch 48/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8792 - mae: 0.7374 - val_loss: 0.8869 - val_mae: 0.7296\n",
      "Epoch 49/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8666 - mae: 0.7264 - val_loss: 0.8977 - val_mae: 0.7347\n",
      "Epoch 50/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8928 - mae: 0.7390 - val_loss: 0.8809 - val_mae: 0.7272\n",
      "Epoch 51/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8883 - mae: 0.7454 - val_loss: 0.8976 - val_mae: 0.7299\n",
      "Epoch 52/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8530 - mae: 0.7239 - val_loss: 0.8805 - val_mae: 0.7244\n",
      "Epoch 53/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9038 - mae: 0.7439 - val_loss: 0.8903 - val_mae: 0.7328\n",
      "Epoch 54/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8511 - mae: 0.7218 - val_loss: 0.8711 - val_mae: 0.7245\n",
      "Epoch 55/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8643 - mae: 0.7261 - val_loss: 0.8781 - val_mae: 0.7226\n",
      "Epoch 56/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8436 - mae: 0.7209 - val_loss: 0.8761 - val_mae: 0.7242\n",
      "Epoch 57/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8974 - mae: 0.7469 - val_loss: 0.8719 - val_mae: 0.7223\n",
      "Epoch 58/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8505 - mae: 0.7136 - val_loss: 0.8758 - val_mae: 0.7248\n",
      "Epoch 59/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8227 - mae: 0.7043 - val_loss: 0.8664 - val_mae: 0.7225\n",
      "Epoch 60/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8260 - mae: 0.7121 - val_loss: 0.8873 - val_mae: 0.7251\n",
      "Epoch 61/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8590 - mae: 0.7202 - val_loss: 0.8691 - val_mae: 0.7243\n",
      "Epoch 62/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9026 - mae: 0.7379 - val_loss: 0.8743 - val_mae: 0.7278\n",
      "Epoch 63/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8610 - mae: 0.7285 - val_loss: 0.8642 - val_mae: 0.7210\n",
      "Epoch 64/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8478 - mae: 0.7116 - val_loss: 0.8640 - val_mae: 0.7229\n",
      "Epoch 65/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8410 - mae: 0.7131 - val_loss: 0.8702 - val_mae: 0.7218\n",
      "Epoch 66/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8240 - mae: 0.7099 - val_loss: 0.8625 - val_mae: 0.7182\n",
      "Epoch 67/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8707 - mae: 0.7242 - val_loss: 0.8823 - val_mae: 0.7233\n",
      "Epoch 68/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8861 - mae: 0.7363 - val_loss: 0.8713 - val_mae: 0.7205\n",
      "Epoch 69/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8556 - mae: 0.7272 - val_loss: 0.8838 - val_mae: 0.7320\n",
      "Epoch 70/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9044 - mae: 0.7440 - val_loss: 0.8700 - val_mae: 0.7180\n",
      "Epoch 71/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8535 - mae: 0.7240 - val_loss: 0.8586 - val_mae: 0.7181\n",
      "Epoch 72/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7928 - mae: 0.6975 - val_loss: 0.8543 - val_mae: 0.7184\n",
      "Epoch 73/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8727 - mae: 0.7257 - val_loss: 0.8820 - val_mae: 0.7217\n",
      "Epoch 74/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8043 - mae: 0.6974 - val_loss: 0.8648 - val_mae: 0.7167\n",
      "Epoch 75/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8205 - mae: 0.6990 - val_loss: 0.8694 - val_mae: 0.7181\n",
      "Epoch 76/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8638 - mae: 0.7311 - val_loss: 0.8778 - val_mae: 0.7252\n",
      "Epoch 77/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8245 - mae: 0.7062 - val_loss: 0.8600 - val_mae: 0.7139\n",
      "Epoch 78/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8323 - mae: 0.7080 - val_loss: 0.8773 - val_mae: 0.7196\n",
      "Epoch 79/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8376 - mae: 0.7116 - val_loss: 0.8613 - val_mae: 0.7155\n",
      "Epoch 80/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8414 - mae: 0.7136 - val_loss: 0.8532 - val_mae: 0.7140\n",
      "Epoch 81/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8176 - mae: 0.7046 - val_loss: 0.8693 - val_mae: 0.7242\n",
      "Epoch 82/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8111 - mae: 0.6941 - val_loss: 0.8642 - val_mae: 0.7135\n",
      "Epoch 83/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8278 - mae: 0.7061 - val_loss: 0.8690 - val_mae: 0.7118\n",
      "Epoch 84/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7862 - mae: 0.6845 - val_loss: 0.8566 - val_mae: 0.7152\n",
      "Epoch 85/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8013 - mae: 0.6868 - val_loss: 0.8575 - val_mae: 0.7128\n",
      "Epoch 86/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8431 - mae: 0.7090 - val_loss: 0.8705 - val_mae: 0.7131\n",
      "Epoch 87/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8345 - mae: 0.7027 - val_loss: 0.8741 - val_mae: 0.7147\n",
      "Epoch 88/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8040 - mae: 0.6956 - val_loss: 0.8577 - val_mae: 0.7117\n",
      "Epoch 89/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8421 - mae: 0.7148 - val_loss: 0.8677 - val_mae: 0.7169\n",
      "Epoch 90/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8016 - mae: 0.6961 - val_loss: 0.8492 - val_mae: 0.7099\n",
      "Epoch 91/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8213 - mae: 0.7096 - val_loss: 0.8812 - val_mae: 0.7332\n",
      "Epoch 92/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8126 - mae: 0.7041 - val_loss: 0.8487 - val_mae: 0.7094\n",
      "Epoch 93/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7806 - mae: 0.6831 - val_loss: 0.8749 - val_mae: 0.7134\n",
      "Epoch 94/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8045 - mae: 0.6905 - val_loss: 0.8438 - val_mae: 0.7106\n",
      "Epoch 95/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8243 - mae: 0.6944 - val_loss: 0.8805 - val_mae: 0.7235\n",
      "Epoch 96/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8103 - mae: 0.6975 - val_loss: 0.8694 - val_mae: 0.7117\n",
      "Epoch 97/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8311 - mae: 0.6984 - val_loss: 0.8790 - val_mae: 0.7160\n",
      "Epoch 98/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7332 - mae: 0.6520 - val_loss: 0.8910 - val_mae: 0.7252\n",
      "Epoch 99/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8256 - mae: 0.7014 - val_loss: 0.8663 - val_mae: 0.7138\n",
      "Epoch 100/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8634 - mae: 0.7225 - val_loss: 0.8733 - val_mae: 0.7148\n"
     ]
    }
   ],
   "source": [
    "# Навчання\n",
    "history = model4.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Оцінка\n",
    "train_mse4, train_mae4 = model4.evaluate(X_train, y_train, verbose=0)\n",
    "val_mse4, val_mae4 = model4.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6734240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.8255, MAE: 0.7079\n",
      "Validation MSE: 0.8438, MAE: 0.7106\n",
      "Prediction for Ukraine (2024): 5.388\n",
      "Actual Score for Ukraine (2024): 4.68\n"
     ]
    }
   ],
   "source": [
    "ukraine_2024 = df[(df[\"Year\"] == 2024) & (df[\"Country\"] == \"Ukraine\")]\n",
    "ukraine_features = scaler.transform(ukraine_2024[features])\n",
    "ukraine_pred4 = model4.predict(ukraine_features, verbose=0)[0][0]\n",
    "ukraine_actual = ukraine_2024[target].values[0]\n",
    "\n",
    "print(f\"Train MSE: {train_mse4:.4f}, MAE: {train_mae4:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse4:.4f}, MAE: {val_mae4:.4f}\")\n",
    "print(f\"Prediction for Ukraine (2024): {ukraine_pred4:.3f}\")\n",
    "print(f\"Actual Score for Ukraine (2024): {ukraine_actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45332f4b",
   "metadata": {},
   "source": [
    "### Model 4: + Stratified Split\n",
    "- ***Logic***: Train/test split stratified by years — important for time-series data to avoid data leakage.\n",
    "- ***Goal***: Improve generalization and reduce dependence on random splitting.\n",
    "- ***Result***:\n",
    "Slightly worse Val MAE: 0.711,\n",
    "Ukraine error 0.708 — better than models 2 and 3.\n",
    "- ***Conclusion***: More stable model with correct splitting approach. Better balance between training fit and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa4fed",
   "metadata": {},
   "source": [
    "# === Model 5: LSTM on country sequences ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69013007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rolling sequences with a window of 3 years\n",
    "window_size = 3\n",
    "\n",
    "def create_sequences(data, features, target, window_size):\n",
    "    Xs, ys = [], []\n",
    "    countries = data[\"Country\"].unique()\n",
    "    for country in countries:\n",
    "        country_data = data[data[\"Country\"] == country].reset_index(drop=True)\n",
    "        for i in range(len(country_data) - window_size + 1):\n",
    "            seq = country_data.loc[i:i+window_size-1, features].values\n",
    "            target_val = country_data.loc[i+window_size-1, target]\n",
    "            Xs.append(seq)\n",
    "            ys.append(target_val)\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X, y = create_sequences(df, features, target, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed6a56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "num_samples, seq_len, num_features = X.shape\n",
    "X_2d = X.reshape(num_samples * seq_len, num_features)\n",
    "scaler = StandardScaler()\n",
    "X_2d_scaled = scaler.fit_transform(X_2d)\n",
    "X_scaled = X_2d_scaled.reshape(num_samples, seq_len, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5826d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aad351a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "model5 = models.Sequential([\n",
    "    layers.Input(shape=(window_size, len(features))),\n",
    "    layers.LSTM(32, activation='tanh', return_sequences=False),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a340c30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 28.0537 - mae: 5.1828 - val_loss: 21.9658 - val_mae: 4.5782\n",
      "Epoch 2/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.1061 - mae: 4.0540 - val_loss: 5.4776 - val_mae: 1.9755\n",
      "Epoch 3/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2789 - mae: 1.7212 - val_loss: 1.2887 - val_mae: 0.9179\n",
      "Epoch 4/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2964 - mae: 0.9239 - val_loss: 0.9818 - val_mae: 0.7917\n",
      "Epoch 5/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0244 - mae: 0.7991 - val_loss: 0.8918 - val_mae: 0.7424\n",
      "Epoch 6/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0029 - mae: 0.7785 - val_loss: 0.8183 - val_mae: 0.7094\n",
      "Epoch 7/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9084 - mae: 0.7451 - val_loss: 0.7915 - val_mae: 0.6946\n",
      "Epoch 8/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9001 - mae: 0.7298 - val_loss: 0.7831 - val_mae: 0.6880\n",
      "Epoch 9/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8607 - mae: 0.7120 - val_loss: 0.7871 - val_mae: 0.6883\n",
      "Epoch 10/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8799 - mae: 0.7200 - val_loss: 0.7678 - val_mae: 0.6781\n",
      "Epoch 11/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9058 - mae: 0.7374 - val_loss: 0.7589 - val_mae: 0.6734\n",
      "Epoch 12/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8085 - mae: 0.6770 - val_loss: 0.7859 - val_mae: 0.6821\n",
      "Epoch 13/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8120 - mae: 0.6922 - val_loss: 0.7650 - val_mae: 0.6732\n",
      "Epoch 14/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8476 - mae: 0.7022 - val_loss: 0.7470 - val_mae: 0.6652\n",
      "Epoch 15/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8435 - mae: 0.7054 - val_loss: 0.7862 - val_mae: 0.6788\n",
      "Epoch 16/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7995 - mae: 0.6680 - val_loss: 0.7652 - val_mae: 0.6716\n",
      "Epoch 17/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7940 - mae: 0.6786 - val_loss: 0.7436 - val_mae: 0.6608\n",
      "Epoch 18/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8057 - mae: 0.6713 - val_loss: 0.7361 - val_mae: 0.6571\n",
      "Epoch 19/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7787 - mae: 0.6780 - val_loss: 0.7364 - val_mae: 0.6576\n",
      "Epoch 20/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7345 - mae: 0.6538 - val_loss: 0.7196 - val_mae: 0.6487\n",
      "Epoch 21/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8041 - mae: 0.6843 - val_loss: 0.7157 - val_mae: 0.6453\n",
      "Epoch 22/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7492 - mae: 0.6520 - val_loss: 0.7099 - val_mae: 0.6411\n",
      "Epoch 23/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7006 - mae: 0.6351 - val_loss: 0.7321 - val_mae: 0.6498\n",
      "Epoch 24/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7760 - mae: 0.6705 - val_loss: 0.7146 - val_mae: 0.6412\n",
      "Epoch 25/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6744 - mae: 0.6153 - val_loss: 0.7208 - val_mae: 0.6423\n",
      "Epoch 26/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7876 - mae: 0.6650 - val_loss: 0.7360 - val_mae: 0.6489\n",
      "Epoch 27/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7239 - mae: 0.6370 - val_loss: 0.7094 - val_mae: 0.6385\n",
      "Epoch 28/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7282 - mae: 0.6428 - val_loss: 0.7055 - val_mae: 0.6353\n",
      "Epoch 29/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7356 - mae: 0.6508 - val_loss: 0.6974 - val_mae: 0.6321\n",
      "Epoch 30/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7581 - mae: 0.6584 - val_loss: 0.7539 - val_mae: 0.6500\n",
      "Epoch 31/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7540 - mae: 0.6497 - val_loss: 0.7321 - val_mae: 0.6417\n",
      "Epoch 32/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7326 - mae: 0.6424 - val_loss: 0.6941 - val_mae: 0.6272\n",
      "Epoch 33/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7969 - mae: 0.6793 - val_loss: 0.7409 - val_mae: 0.6424\n",
      "Epoch 34/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7694 - mae: 0.6548 - val_loss: 0.7013 - val_mae: 0.6283\n",
      "Epoch 35/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7711 - mae: 0.6604 - val_loss: 0.7098 - val_mae: 0.6330\n",
      "Epoch 36/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7297 - mae: 0.6401 - val_loss: 0.7167 - val_mae: 0.6370\n",
      "Epoch 37/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7529 - mae: 0.6483 - val_loss: 0.7248 - val_mae: 0.6368\n",
      "Epoch 38/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7692 - mae: 0.6578 - val_loss: 0.6918 - val_mae: 0.6265\n",
      "Epoch 39/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7676 - mae: 0.6611 - val_loss: 0.6961 - val_mae: 0.6272\n",
      "Epoch 40/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7257 - mae: 0.6374 - val_loss: 0.7380 - val_mae: 0.6416\n",
      "Epoch 41/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7152 - mae: 0.6276 - val_loss: 0.6894 - val_mae: 0.6201\n",
      "Epoch 42/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7522 - mae: 0.6467 - val_loss: 0.6868 - val_mae: 0.6205\n",
      "Epoch 43/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7532 - mae: 0.6504 - val_loss: 0.6873 - val_mae: 0.6224\n",
      "Epoch 44/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7003 - mae: 0.6268 - val_loss: 0.7496 - val_mae: 0.6452\n",
      "Epoch 45/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7204 - mae: 0.6333 - val_loss: 0.7252 - val_mae: 0.6342\n",
      "Epoch 46/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6832 - mae: 0.6019 - val_loss: 0.6835 - val_mae: 0.6179\n",
      "Epoch 47/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7136 - mae: 0.6253 - val_loss: 0.6870 - val_mae: 0.6179\n",
      "Epoch 48/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6937 - mae: 0.6156 - val_loss: 0.6815 - val_mae: 0.6180\n",
      "Epoch 49/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7401 - mae: 0.6533 - val_loss: 0.7374 - val_mae: 0.6374\n",
      "Epoch 50/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7778 - mae: 0.6542 - val_loss: 0.7012 - val_mae: 0.6221\n",
      "Epoch 51/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7233 - mae: 0.6384 - val_loss: 0.6886 - val_mae: 0.6229\n",
      "Epoch 52/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7266 - mae: 0.6198 - val_loss: 0.7790 - val_mae: 0.6569\n",
      "Epoch 53/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7157 - mae: 0.6266 - val_loss: 0.6909 - val_mae: 0.6178\n",
      "Epoch 54/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7138 - mae: 0.6323 - val_loss: 0.6866 - val_mae: 0.6163\n",
      "Epoch 55/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7646 - mae: 0.6520 - val_loss: 0.6772 - val_mae: 0.6122\n",
      "Epoch 56/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7150 - mae: 0.6250 - val_loss: 0.7161 - val_mae: 0.6287\n",
      "Epoch 57/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7410 - mae: 0.6409 - val_loss: 0.6756 - val_mae: 0.6125\n",
      "Epoch 58/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7473 - mae: 0.6334 - val_loss: 0.6762 - val_mae: 0.6119\n",
      "Epoch 59/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7678 - mae: 0.6499 - val_loss: 0.6998 - val_mae: 0.6211\n",
      "Epoch 60/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6633 - mae: 0.6026 - val_loss: 0.6901 - val_mae: 0.6184\n",
      "Epoch 61/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6263 - mae: 0.5801 - val_loss: 0.6693 - val_mae: 0.6082\n",
      "Epoch 62/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6803 - mae: 0.6158 - val_loss: 0.6713 - val_mae: 0.6079\n",
      "Epoch 63/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6968 - mae: 0.6161 - val_loss: 0.7133 - val_mae: 0.6247\n",
      "Epoch 64/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7004 - mae: 0.6118 - val_loss: 0.6919 - val_mae: 0.6181\n",
      "Epoch 65/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7184 - mae: 0.6219 - val_loss: 0.6703 - val_mae: 0.6091\n",
      "Epoch 66/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6791 - mae: 0.6018 - val_loss: 0.7010 - val_mae: 0.6213\n",
      "Epoch 67/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7045 - mae: 0.6207 - val_loss: 0.6991 - val_mae: 0.6188\n",
      "Epoch 68/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6964 - mae: 0.6221 - val_loss: 0.6810 - val_mae: 0.6098\n",
      "Epoch 69/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7040 - mae: 0.6195 - val_loss: 0.6698 - val_mae: 0.6054\n",
      "Epoch 70/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6566 - mae: 0.5952 - val_loss: 0.6757 - val_mae: 0.6088\n",
      "Epoch 71/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6698 - mae: 0.5978 - val_loss: 0.6675 - val_mae: 0.6050\n",
      "Epoch 72/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6781 - mae: 0.6079 - val_loss: 0.7039 - val_mae: 0.6224\n",
      "Epoch 73/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6809 - mae: 0.6050 - val_loss: 0.6733 - val_mae: 0.6068\n",
      "Epoch 74/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6944 - mae: 0.6148 - val_loss: 0.6645 - val_mae: 0.6017\n",
      "Epoch 75/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7168 - mae: 0.6274 - val_loss: 0.6842 - val_mae: 0.6090\n",
      "Epoch 76/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6901 - mae: 0.6113 - val_loss: 0.6877 - val_mae: 0.6140\n",
      "Epoch 77/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6951 - mae: 0.6023 - val_loss: 0.6873 - val_mae: 0.6102\n",
      "Epoch 78/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6834 - mae: 0.6023 - val_loss: 0.6626 - val_mae: 0.6005\n",
      "Epoch 79/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6584 - mae: 0.5956 - val_loss: 0.6662 - val_mae: 0.6023\n",
      "Epoch 80/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7007 - mae: 0.6141 - val_loss: 0.7613 - val_mae: 0.6381\n",
      "Epoch 81/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6578 - mae: 0.5951 - val_loss: 0.6925 - val_mae: 0.6148\n",
      "Epoch 82/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7331 - mae: 0.6326 - val_loss: 0.7212 - val_mae: 0.6261\n",
      "Epoch 83/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6683 - mae: 0.6039 - val_loss: 0.6750 - val_mae: 0.6075\n",
      "Epoch 84/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6635 - mae: 0.5892 - val_loss: 0.6706 - val_mae: 0.6022\n",
      "Epoch 85/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7152 - mae: 0.6293 - val_loss: 0.6669 - val_mae: 0.6013\n",
      "Epoch 86/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6346 - mae: 0.5863 - val_loss: 0.6892 - val_mae: 0.6130\n",
      "Epoch 87/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7251 - mae: 0.6230 - val_loss: 0.6584 - val_mae: 0.5950\n",
      "Epoch 88/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7325 - mae: 0.6342 - val_loss: 0.7130 - val_mae: 0.6185\n",
      "Epoch 89/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6840 - mae: 0.6116 - val_loss: 0.6903 - val_mae: 0.6116\n",
      "Epoch 90/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7080 - mae: 0.6111 - val_loss: 0.6991 - val_mae: 0.6148\n",
      "Epoch 91/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6732 - mae: 0.5902 - val_loss: 0.6747 - val_mae: 0.6054\n",
      "Epoch 92/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7259 - mae: 0.6216 - val_loss: 0.7377 - val_mae: 0.6325\n",
      "Epoch 93/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7013 - mae: 0.6028 - val_loss: 0.6725 - val_mae: 0.6000\n",
      "Epoch 94/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6477 - mae: 0.5788 - val_loss: 0.6623 - val_mae: 0.5946\n",
      "Epoch 95/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6993 - mae: 0.6077 - val_loss: 0.6574 - val_mae: 0.5935\n",
      "Epoch 96/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6811 - mae: 0.6055 - val_loss: 0.6581 - val_mae: 0.5947\n",
      "Epoch 97/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7564 - mae: 0.6382 - val_loss: 0.6754 - val_mae: 0.6019\n",
      "Epoch 98/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6656 - mae: 0.5912 - val_loss: 0.7293 - val_mae: 0.6289\n",
      "Epoch 99/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7085 - mae: 0.6095 - val_loss: 0.7288 - val_mae: 0.6220\n",
      "Epoch 100/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7211 - mae: 0.6138 - val_loss: 0.6971 - val_mae: 0.6102\n",
      "Epoch 101/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7178 - mae: 0.6201 - val_loss: 0.6878 - val_mae: 0.6134\n",
      "Epoch 102/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7004 - mae: 0.6079 - val_loss: 0.6544 - val_mae: 0.5877\n",
      "Epoch 103/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7020 - mae: 0.6183 - val_loss: 0.6606 - val_mae: 0.5953\n",
      "Epoch 104/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7005 - mae: 0.6049 - val_loss: 0.6635 - val_mae: 0.5953\n",
      "Epoch 105/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6669 - mae: 0.5879 - val_loss: 0.6699 - val_mae: 0.6036\n",
      "Epoch 106/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7338 - mae: 0.6176 - val_loss: 0.6710 - val_mae: 0.6023\n",
      "Epoch 107/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6509 - mae: 0.5873 - val_loss: 0.6608 - val_mae: 0.5927\n",
      "Epoch 108/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7060 - mae: 0.6048 - val_loss: 0.6575 - val_mae: 0.5903\n",
      "Epoch 109/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7072 - mae: 0.6075 - val_loss: 0.6909 - val_mae: 0.6042\n",
      "Epoch 110/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6754 - mae: 0.5873 - val_loss: 0.6678 - val_mae: 0.5982\n",
      "Epoch 111/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6807 - mae: 0.5989 - val_loss: 0.6595 - val_mae: 0.5901\n",
      "Epoch 112/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7102 - mae: 0.6119 - val_loss: 0.6651 - val_mae: 0.5921\n",
      "Epoch 113/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6698 - mae: 0.5863 - val_loss: 0.6714 - val_mae: 0.6016\n",
      "Epoch 114/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7198 - mae: 0.6084 - val_loss: 0.6716 - val_mae: 0.5941\n",
      "Epoch 115/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6856 - mae: 0.6078 - val_loss: 0.7071 - val_mae: 0.6107\n",
      "Epoch 116/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6604 - mae: 0.5846 - val_loss: 0.6779 - val_mae: 0.5975\n",
      "Epoch 117/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6414 - mae: 0.5821 - val_loss: 0.6558 - val_mae: 0.5945\n"
     ]
    }
   ],
   "source": [
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "# Train\n",
    "history = model5.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0732c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.6918, MAE: 0.6092\n",
      "Validation MSE: 0.6544, MAE: 0.5877\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_mse5, train_mae5 = model5.evaluate(X_train, y_train, verbose=0)\n",
    "val_mse5, val_mae5 = model5.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print(f\"Train MSE: {train_mse5:.4f}, MAE: {train_mae5:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse5:.4f}, MAE: {val_mae5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0915ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3140f3740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Ukraine 2024 Prediction (LSTM): 5.435\n",
      "Ukraine 2024 Actual: 4.68\n"
     ]
    }
   ],
   "source": [
    "ukraine_data = df[df[\"Country\"] == \"Ukraine\"].sort_values(\"Year\")\n",
    "ukraine_seq = ukraine_data[features].iloc[-window_size:].values\n",
    "ukraine_seq_scaled = scaler.transform(ukraine_seq).reshape(1, window_size, len(features))\n",
    "\n",
    "ukraine_pred5 = model5.predict(ukraine_seq_scaled, verbose=0)[0][0]\n",
    "ukraine_actual = ukraine_data[target].iloc[-1]\n",
    "\n",
    "print(f\"Ukraine 2024 Prediction (LSTM): {ukraine_pred5:.3f}\")\n",
    "print(f\"Ukraine 2024 Actual: {ukraine_actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba03ee",
   "metadata": {},
   "source": [
    "### Model 5: LSTM\n",
    "- ***Logic***: Shift to a sequential model (LSTM) that accounts for temporal dynamics of countries over years. Each sample is a sequence of indicators over 3 years.\n",
    "- ***Goal***: Capture the time structure of the data, not just “year as a feature” but historical changes over time.\n",
    "- ***Result***:\n",
    "Best overall performance: Val MAE = 0.588, Train MAE = 0.609,\n",
    "Ukraine 2024 Abs Error = 0.755 — not the best, but decent.\n",
    "- ***Conclusion***: LSTM generalizes best across all countries (lowest MAE) but is less adapted to unusual or abnormal situations (like the war in Ukraine), where historical data may not provide precise predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f9710",
   "metadata": {},
   "source": [
    "# === Result ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19859722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Val MSE</th>\n",
       "      <th>Val MAE</th>\n",
       "      <th>Ukraine 2024 Prediction</th>\n",
       "      <th>Ukraine 2024 Actual</th>\n",
       "      <th>Abs Error (Ukraine 2024)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1: Basic NN</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.704</td>\n",
       "      <td>5.243</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2: Deeper NN + Dropout</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.702</td>\n",
       "      <td>5.670</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3: + Year</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.680</td>\n",
       "      <td>5.537</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4: + Stratified Split</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.711</td>\n",
       "      <td>5.388</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5: LSTM</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.588</td>\n",
       "      <td>5.435</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Train MSE  Train MAE  Val MSE  Val MAE  \\\n",
       "0             Model 1: Basic NN      0.853      0.700    0.826    0.704   \n",
       "1  Model 2: Deeper NN + Dropout      0.903      0.747    0.797    0.702   \n",
       "2               Model 3: + Year      0.820      0.680    0.791    0.680   \n",
       "3   Model 4: + Stratified Split      0.826      0.708    0.844    0.711   \n",
       "4                 Model 5: LSTM      0.692      0.609    0.654    0.588   \n",
       "\n",
       "   Ukraine 2024 Prediction  Ukraine 2024 Actual  Abs Error (Ukraine 2024)  \n",
       "0                    5.243                 4.68                     0.563  \n",
       "1                    5.670                 4.68                     0.990  \n",
       "2                    5.537                 4.68                     0.857  \n",
       "3                    5.388                 4.68                     0.708  \n",
       "4                    5.435                 4.68                     0.755  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    \"Model\": [\"Model 1: Basic NN\", \"Model 2: Deeper NN + Dropout\", \"Model 3: + Year\", \n",
    "              \"Model 4: + Stratified Split\", \"Model 5: LSTM\"],\n",
    "    \"Train MSE\": [train_mse1, train_mse2, train_mse3, train_mse4, train_mse5],\n",
    "    \"Train MAE\": [train_mae1, train_mae2, train_mae3, train_mae4, train_mae5],\n",
    "    \"Val MSE\": [val_mse1, val_mse2, val_mse3, val_mse4, val_mse5],\n",
    "    \"Val MAE\": [val_mae1, val_mae2, val_mae3, val_mae4, val_mae5],\n",
    "    \"Ukraine 2024 Prediction\": [ukraine_pred1, ukraine_pred2, ukraine_pred3, ukraine_pred4, ukraine_pred5],\n",
    "    \"Ukraine 2024 Actual\": [real, actual_ukraine, ukraine_actual, ukraine_actual, ukraine_actual],\n",
    "    \"Abs Error (Ukraine 2024)\": [\n",
    "        abs(ukraine_pred1 - real),\n",
    "        abs(ukraine_pred2 - actual_ukraine),\n",
    "        abs(ukraine_pred3 - ukraine_actual),\n",
    "        abs(ukraine_pred4 - ukraine_actual),\n",
    "        abs(ukraine_pred5 - ukraine_actual)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.round(3)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc80591",
   "metadata": {},
   "source": [
    "**Model 5**, based on the Long Short-Term Memory (LSTM) architecture, was chosen because it effectively captures the temporal dynamics and sequential patterns in the World Happiness dataset across multiple years. Unlike traditional feedforward networks that treat each year as an independent sample, LSTM leverages historical data over a 3-year window for each country, allowing the model to learn how changes in features evolve over time and influence the happiness score.\n",
    "\n",
    "This temporal awareness leads to the best overall validation performance, reflected in the lowest validation mean absolute error (**MAE = 0.588**) and mean squared error (MSE), indicating superior generalization ability across countries and years.\n",
    "\n",
    "Although the Ukraine 2024 prediction error is not the absolute lowest among all models, the LSTM’s strength in modeling trends and sequences makes it the most robust and promising model for forecasting happiness, especially when working with multi-year panel data.\n",
    "\n",
    "Therefore, Model 5 is preferred for its ability to incorporate the sequential structure of the data, improving predictive accuracy and offering a more nuanced understanding of happiness trends over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
